
<!-- 
NEED TO INSERT THE BODY AND ALL THE USEFUL STUFF HERE
-->

<html>

<!-- Mirrored from www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-mathematical-foundations/variance-and-standard-deviation by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 01 Aug 2021 17:05:55 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<!-- title should be set at this point in page.php -->
<title>Mathematical Foundations of Monte Carlo Methods (Variance and Standard Deviation)</title>

<meta name='author' content="Scratchapixel">
<meta name='copyright' content="&copy; 2009-2016 Scratchapixel">
<meta name='keywords' content='Monte Carlo methods, Monte Carlo integration, random variables, probability, statistics, expected value, variance, standard deviation, probability distribution, probability density function, PDF, cumulative distribution function, CDF, inverse transform sampling method, estimator'>
<meta name='date' content='2015-04-18 15:13:02'>

<link rel="stylesheet" type="text/css" href="../../../css/scratchapixel.css"/>
<link rel="stylesheet" type="text/css" href="../../../css/page.css"/>

<link href='../../../../fonts.googleapis.com/css16e1.css?family=Noto+Sans' rel='stylesheet' type='text/css'/>
<link href='../../../../fonts.googleapis.com/css9908.css?family=Open+Sans:700,400,300' rel='stylesheet' type='text/css'/>

<!-- using the material icons from Google http://google.github.io/material-design-icons/ -->
<link rel="stylesheet" href="../../../../fonts.googleapis.com/icone91f.css?family=Material+Icons">

<script type="text/x-mathjax-config">
MathJax.Hub.Config(
	{tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}, 
	displayAlign: "left",
	displayIndent: "1em",
	"HTML-CSS": { scale: 90 },
	jax: ["input/TeX","input/MathML","input/AsciiMath","output/HTML-CSS","output/NativeMML"],
	extensions: ["tex2jax.js","../../../indexf17c.html","../../../indexf17c.html","../../../indexf17c.html","MathZoom.js"],
	TeX: {
		extensions: ["AMSmath.js","../../../indexf17c.html","../../../indexf17c.html","noUndefined.js"]
	}}
);
</script>

<script type="text/javascript" src="../../../../cdn.mathjax.org/mathjax/latest/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript"
	src="../../../scratchapixelSDK.js">
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','../../../../www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-42771397-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- 
https://developers.facebook.com/docs/plugins/share-button/
Include the JavaScript SDK on your page once, ideally right after the opening <body> tag.
-->

<script>
  window.fbAsyncInit = function() {
	FB.init({
	  appId      : '1535346446701691',
	  xfbml      : true,
	  version    : 'v2.1'
	});
  };

  (function(d, s, id){
	 var js, fjs = d.getElementsByTagName(s)[0];
	 if (d.getElementById(id)) {return;}
	 js = d.createElement(s); js.id = id;
	 js.src = "../../../../connect.facebook.net/en_US/sdk.js";
	 fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>

<script>
	!function(d,s,id) {
		var js,fjs=d.getElementsByTagName(s)[0];
		if(!d.getElementById(id)) {
			js=d.createElement(s);js.id=id;
			js.src="../../../../platform.twitter.com/widgets.js";
			fjs.parentNode.insertBefore(js,fjs);
		}
	}(document,"script","twitter-wjs");
</script>


</head>

<style>
.full-page1
{
	position: relative;
	margin: 0; padding: 0; 
	width: 100%; 
	border: 1px solid red;
	color: white;
}

.full-page-header-table1
{
	display: table; 
	width: 100%;
	border: 1px solid orange;
}
</style>

<div style='display: table; width: 100%;'>
	<!-- 
		This should be the content of the top menu bar. So if you want to reuse
		this, just create a table div above and insert the section.
		The height here doesn't mater because it's controlled by the inner table.
-->
<div style='display: table-row;  height: 40px; width: 100%; background-color: #1565C0; color: white;'>
	<!-- we center the cell in the middle of the row -->
	<div style='display: table-cell; width: 100%; border: 1px none orange; vertical-align: middle; text-align: center;'>
		
		<div style='display: inline-block; position: relative; border: 1px none black; width: 670px; margin: 0 auto; padding: 0;'>			
			<!-- 
				This is our logo 
			-->
			<div style='display: inline-block; border: 2px none green;'>
				<span style='font-size: 18px; font-weight: 800;'><a href='../../../indexf17c.html' style='text-decoration: none; color: white;'>Scratchapixel 2.0</a></span>
			</div>
			<!-- 
				This is login 
				The only way you can vertically center stuff here is by forcing the height of the div
				and the eight of the text to be the same
			-->
			<div style='border: 2px none green; position: absolute; right: 0;  top: 0; bottom: 0px; height: 20px; line-height: 20px; margin: auto 0;'>
				<a style="color: white; text-decoration: none;" href="https://www.facebook.com/v2.5/dialog/oauth?client_id=1682406642074489&amp;state=6241aa28239e903f6cad376e5bc19dd1&amp;response_type=code&amp;sdk=php-sdk-5.4.0&amp;redirect_uri=https%3A%2F%2Fwww.scratchapixel.com%2Ffb-callback.php%3F&amp;scope=email">Sign in</a>			</div>
			
		</div>
	</div>
</div></div>

<body onload="onload();">

<div id='fb-root'></div> <!-- that's required by FB -->
<div class="page-content">
<article><div id='sap-root'></div><!-- that's needed by scratchapixel see onload() --><div class='lesson-title'>Mathematical Foundations of Monte Carlo Methods</div><div class='chapter-table'><div class='chapter-row'><div class='chapter-cell'><b>Contents</b></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="quick-introduction-to-monte-carlo-methods.html">A Quick Introduction to Monte Carlo Methods</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="random-variables-and-probability.html">Random Variables and Probability</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-distribution-part1.html">Probability Distribution: Part 1</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-properties.html">Probability Properties</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="introduction-to-statistics.html">Introduction to Statistics</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="expected-value.html">Expected Value</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="variance-and-standard-deviation.html"><b>Variance and Standard Deviation</b></a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-distribution-part2.html">Probability Distribution: Part 2</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="sampling-distribution.html">Sampling Distribution</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="pdf-and-cdf.html">Probability Density Function (PDF) and Cumulative Distribution Function (CDF)</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="expected-value-of-the-function-of-a-random-variable.html">Expected Value of the Function of a Random Variable: Law of the Unconscious Statistician</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="inverse-transform-sampling-method.html">The Inverse Transform Sampling Method</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="estimators.html">Estimators</a></div></div></div><h2>Variance and Standard Deviation</h2>

<p>Imagine that you measure the height of a certain number of trees which have grown for the same amount of time. Most trees have probably all grown more or less the same way thus after let's say 10 years, you expect them to have all more or less the same height, however some trees may have a much smaller height than what you would expect. However saying that a tree is smaller than you would expect requires that you can define what's you expect the average height of a 10 years old tree to be in the first place, and of course, since trees are unlikely to have exactly the same height, it requires that you also define an interval within which you accept some level of variation from this average. Only then can a tree whose height does not fall within this interval (centred around the average tree height) be considered as unusually taller or unusually smaller than the rest of the trees (this can be very useful in statistics to define for example whether a particular individual from a given population and of a given age, follows a normal growth rate). Computing the average tree height is simple: you just add up all the trees height and divide the resulting number by the total number of trees. But how do we compute the range of variation within which a tree height can be considered normal or not? This is where <b>variance</b> and <b>standard deviation</b> come into play. Standard deviation is simply the square root of variance, thus we will just concentrate on variance for now. Technically variance is defined as the expected value of the square difference between the outcome of the experiment (let's say the height of each tree) and its expected value (in the tree example, the tree average height). Variance can be expressed as:</p>

$$Var(X) = \sigma^2 = E[(X - E[X])^2] = \sum_i (x_i - E[X])^2p_i.$$

<p>We know that \(E[X] = \sum_{i=1} p_i x_i\) thus if we set \(x = (a - b)^2\) we get \(E[(a-b)^2] = \sum_{i=1} (a-b)_i^2 p_i\) where in our example, \((a-b)^2 = (x - E[X])^2\). That is really all there is to the equation above. The symbol \(\sigma\) is the greek letter sigma (and you can read variance as "sigma squared"). The definition of variance is hard to make sense of but the concept is actually simple. For instance you take the difference between the height of the first tree and the expected value which in this example is the average tree height, you take the square of this number, repeat this process for all the remaining trees and add up the numbers. This gives you the variance for the height of the trees. And taking the square root of this number gives you the standard deviation:</p>

$$\text{standard deviation }= \sqrt { \sigma^2}.$$

<p>Since we are in the realm of statistics, large numbers and probability here, this number can be interpreted as being an acceptable variation of the height above or below the average value within which you can consider the height of any tree to be a valid representation of the overall tree population's height.</p>

<img class="right" src="../../../images/upload/monte-carlo-methods/deviation2d41d.png?" />

<p>This can also be seen as some average distance between the points of a set of data points, where the data set in our example is our collection of trees (see the example below) or put it differently, the average distance from the mean of all the samples. The expected value is additive, \(E[f+g] = E[f] + E[g]\) and the expected value of a constant is that constant (\(E[c] =c \)) thus if we write \(\mu = E[X]\) (where \(\mu\), the greek letter mu, in statistics, designates the population mean or population expected value (see previous chapter for more information on this and expected value properties). In our tree example for instance, this is the average tree height calculated from summing up the the height of all the trees and dividing the resulting number by the total number of trees). The expression for variance can be expanded into:</p>

$$
\begin{array}{l}
E[(X - E[X])^2] & = & E[(X - \mu)^2] \\
& = & E[X^2 + \mu^2 - 2 X\mu] \\ 
& = & E[X^2] -2E[X]\mu + E[\mu^2] \\
& = & E[X^2] - 2\mu^2 + \mu^2 \\
& = & E[X^2] - \mu^2 \\
& = & \sum_i x_i^2 p_i - (\sum_i x_i p_i)^2 \\
& = & \sum_i x_i^2 p_i - \mu^2.
\end{array}
$$

<p>This formulation is useful in computing because as you go through the elements to compute the population mean you can also compute the left term (the sum). And the end of this process, you are left with subtracting the population mean form the sum of the squared observations (see the chapter on sampling distribution for an example). Of course the technique works whether you consider all the elements in the population or just the elements from a sample of certain size. When you consider the entire population the term on the right is the population mean. If you work from a sample, it would be more accurate to call the term on the right the sample mean (which, if the sample size is large enough, is also the expected value of the random variable). If all random variables have the same probability then note that we can also write (we assume here that we work from a sample of size \(n\)):</p>

$$Var(X) = \sum_{i=1}^n{{ (x_i - \bar X)^2} \over n }.$$

<p>Where \(n\) is the total number of random variables being considered in the calculation of the sample mean.</p>

<div class="question">
<b>Example</b>: consider two data sets, set A in which you have the data points {-10, 0, 10, 20, 30} and set B in which you have the data points {8, 9, 10, 12, 12}. If we were to compute the mean of these data sets we would get (-10+0+10+20+30)/50=10 in the first case, and (8+9+10+11+12)/5=10 in the second case. In other words, both sets have the same mean, thus one could think that the sets are quite similar, however looking at the numbers you can tell they are not. It is pretty clear that in the first set the data are far much further apart from each other than with the data in set B. If we were to compute the variance of each data set we would get:</br>

$$
\begin{array}{l}Var(A) =\sigma_A^2 \\ {\dfrac{(-10-10)^2+(0-10)^2+(10-10)^2+(20-10)^2+(30-10)^2}{5}}= \\{\dfrac{1000}{5}} = 200\\Var(B) = \sigma_B^2 \\ {\dfrac{(8-10)^+(9-10)^2+(10-10)^2+(11-10)^2+(12-10)^2}{5}}= \\\dfrac{10}{5}=2.\end{array}
$$

You want the average difference between each sample and the sample mean, thus you divide the sum of these numbers by the size of the data set (5 in our example). The standard deviation of the set A are set B would be:</br>

$$\sigma_A = \sqrt {200} = 10\sqrt{2} \text{, } \sigma_B = \sqrt{2}.$$

<p>We can say that the standard deviation of set A is 10 times greater than the standard deviation of set B. Note that if the units of the data points are distance for instance, the unit of variance would be square meters for instance (if we use meters as our unit to measure distances) and standard deviation would be expressed in meters.</p>

<p>If you haven't noticed yet, the main reason why the difference between the random variable (an item of the data set) and the data set mean is raised to the power of 2 is to get rid of the potential sign when the result of this difference is negative (it removes the effect of whether or not the difference is positive or negative).</p>
</div>

<h2>Properties of Variance</h2>

<p>Properties of variance are quite important to understand or interpret some of the techniques we will introduce next. It is important to know wat they are. Not susprisingly they are very similar to the expected value properties:</p>

<ul>
<li>If \(Pr(X = c) = 1\), then \(Var(X) = 0\). This requires a short explanation. If we have an experiment which is always returning the exact same outcome (this outcome's probability is 1), thus the variance is simply 0. More formally if there exists a constant \(c\) such that \(Pr(X = c) = 1\), then \(E[c] = c\) (see expectations properties), and \(Pr[(X - c)^2 = 0] = 1\). Therefore \(Var(X) = E[(X-c)^2] = 0\).</li>

<li>If we note \(Y = aX + b\) then $$Var(Y) = a^2 Var(X).$$If \(E[X] = \mu\), then \(E[Y] = a\mu + b\) (see expectations' properties).
Thus we can write:

$$
\begin{array}{l}
Var(Y) &=& E[(aX + b - a\mu -b)^2] = E[(aX - a\mu)^2]\\
&=&a^2E[(X-\mu)^2]=a^2Var(X).
\end{array}
$$

Note that \(Var(X + b) = Var(X)\). Again, this is easy to understand. Shifting the height of all the trees by the same amount won't change the population's variance. The expected value will change but not variance.</li>

<li>If \(X_1, ..., X_n\) are independent random variables, then: 

$$Var(X_1 + ... + X_n) = Var(X_1) + ... + Var(X_n).$$

Let's prove this properly using two random variables \(X_1\) and \(X_2\)) (\(n = 2\)). If \(E[X_1] = \mu_1\) and \(E[X_2] = \mu_2\), then:

$$E[X_1 + X_2] = \mu_1 + \mu_2.$$

Therefore:

$$
\begin{array}{l} 
Var(X_1 + X_2) &=& E[(X_1 + X_2 + \mu_1 + \mu_2)^2]\\
&=&E[(X_1-\mu_1)^2 + (X_2 - \mu_2)^2 + 2(X_1 - \mu_1)(X_2 - \mu_2)]\\
&=&Var(X_1) + Var(X_2) + 2E[(X_1-\mu_1)(X_2 - \mu_2)].
\end{array}
$$

\(X_1\) and \(X_2\) are independent, thus:

$$
\begin{array}{l}
E[(X_1-\mu_1)(X_2-\mu_2)] &=& E[(X_1-\mu_1)]E[(X_2 - \mu_2)]\\
&=&(\mu_1 - \mu_1)(\mu_2 - \mu_2)\\
&=&0.
\end{array}

$$
Finally, we are left with:$$Var(X_1 + X_2) = Var(X_1) + Var(X_2).$$</li>
</ul>

<div class="question">
Using the four following equations (keep in mind that the expected value of a random value is a constant, so the expected value of an expected value (a constant) is the expected value itself - fourth equation):</br>

$$
\begin{array}{l}
E[X + c] = E[X] + c, \\ E[cX] = c E[X], \\ E[X +Y] = E[X]+E[Y],\\E[E[X] = E[X].
\end{array}
$$

<p>We can transform the equation for variance (recall that \((a - b)^2 = a^2 + b^2 - 2ab\)):</p>

$$
\begin{array}{l} 
Var(X) &=& E[(X - E[X])^2] \\ & =& E[X^2 - 2X E[X] + E[X]^2],\\
& =& E[X^2] - 2 E[X] E[X] + E[X]^2, \\ 
& =& E[X^2] - E[X]^2.
\end{array}
$$

<p>This equation is simpler than the original equation.</p>
</div></article></div><!-- end of page-content -->
			<div class='footer-prev-next'>
			<div class='footer-column'><div class='footer-prev-next-row'>
				<div class='footer-prev-next-cell' style='text-align: left;'><p><a href='expected-value.html'><i style='float: left;' class='material-icons'>arrow_back</i>Previous Chapter</a></p></div>
				<div class='footer-prev-next-cell' style='text-align: center;'><p>Chapter 7 of  13</p></div>
				<div class='footer-prev-next-cell' style='text-align: right;'><p><a href='probability-distribution-part2.html'>Next Chapter <i style='float: right;' class='material-icons'>arrow_forward</i></a></p></div>
			</div></div>
			</div>

</body>

<!-- Mirrored from www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-mathematical-foundations/variance-and-standard-deviation by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 01 Aug 2021 17:06:00 GMT -->
</html>