
<!-- 
NEED TO INSERT THE BODY AND ALL THE USEFUL STUFF HERE
-->

<html>

<!-- Mirrored from www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-mathematical-foundations/random-variables-and-probability by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 01 Aug 2021 17:05:30 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<!-- title should be set at this point in page.php -->
<title>Mathematical Foundations of Monte Carlo Methods (Random Variables and Probability)</title>

<meta name='author' content="Scratchapixel">
<meta name='copyright' content="&copy; 2009-2016 Scratchapixel">
<meta name='keywords' content='Monte Carlo methods, Monte Carlo integration, random variables, probability, statistics, expected value, variance, standard deviation, probability distribution, probability density function, PDF, cumulative distribution function, CDF, inverse transform sampling method, estimator'>
<meta name='date' content='2015-04-18 15:13:02'>

<link rel="stylesheet" type="text/css" href="../../../css/scratchapixel.css"/>
<link rel="stylesheet" type="text/css" href="../../../css/page.css"/>

<link href='../../../../fonts.googleapis.com/css16e1.css?family=Noto+Sans' rel='stylesheet' type='text/css'/>
<link href='../../../../fonts.googleapis.com/css9908.css?family=Open+Sans:700,400,300' rel='stylesheet' type='text/css'/>

<!-- using the material icons from Google http://google.github.io/material-design-icons/ -->
<link rel="stylesheet" href="../../../../fonts.googleapis.com/icone91f.css?family=Material+Icons">

<script type="text/x-mathjax-config">
MathJax.Hub.Config(
	{tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}, 
	displayAlign: "left",
	displayIndent: "1em",
	"HTML-CSS": { scale: 90 },
	jax: ["input/TeX","input/MathML","input/AsciiMath","output/HTML-CSS","output/NativeMML"],
	extensions: ["tex2jax.js","../../../indexf17c.html","../../../indexf17c.html","../../../indexf17c.html","MathZoom.js"],
	TeX: {
		extensions: ["AMSmath.js","../../../indexf17c.html","../../../indexf17c.html","noUndefined.js"]
	}}
);
</script>

<script type="text/javascript" src="../../../../cdn.mathjax.org/mathjax/latest/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript"
	src="../../../scratchapixelSDK.js">
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','../../../../www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-42771397-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- 
https://developers.facebook.com/docs/plugins/share-button/
Include the JavaScript SDK on your page once, ideally right after the opening <body> tag.
-->

<script>
  window.fbAsyncInit = function() {
	FB.init({
	  appId      : '1535346446701691',
	  xfbml      : true,
	  version    : 'v2.1'
	});
  };

  (function(d, s, id){
	 var js, fjs = d.getElementsByTagName(s)[0];
	 if (d.getElementById(id)) {return;}
	 js = d.createElement(s); js.id = id;
	 js.src = "../../../../connect.facebook.net/en_US/sdk.js";
	 fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>

<script>
	!function(d,s,id) {
		var js,fjs=d.getElementsByTagName(s)[0];
		if(!d.getElementById(id)) {
			js=d.createElement(s);js.id=id;
			js.src="../../../../platform.twitter.com/widgets.js";
			fjs.parentNode.insertBefore(js,fjs);
		}
	}(document,"script","twitter-wjs");
</script>


</head>

<style>
.full-page1
{
	position: relative;
	margin: 0; padding: 0; 
	width: 100%; 
	border: 1px solid red;
	color: white;
}

.full-page-header-table1
{
	display: table; 
	width: 100%;
	border: 1px solid orange;
}
</style>

<div style='display: table; width: 100%;'>
	<!-- 
		This should be the content of the top menu bar. So if you want to reuse
		this, just create a table div above and insert the section.
		The height here doesn't mater because it's controlled by the inner table.
-->
<div style='display: table-row;  height: 40px; width: 100%; background-color: #1565C0; color: white;'>
	<!-- we center the cell in the middle of the row -->
	<div style='display: table-cell; width: 100%; border: 1px none orange; vertical-align: middle; text-align: center;'>
		
		<div style='display: inline-block; position: relative; border: 1px none black; width: 670px; margin: 0 auto; padding: 0;'>			
			<!-- 
				This is our logo 
			-->
			<div style='display: inline-block; border: 2px none green;'>
				<span style='font-size: 18px; font-weight: 800;'><a href='../../../indexf17c.html' style='text-decoration: none; color: white;'>Scratchapixel 2.0</a></span>
			</div>
			<!-- 
				This is login 
				The only way you can vertically center stuff here is by forcing the height of the div
				and the eight of the text to be the same
			-->
			<div style='border: 2px none green; position: absolute; right: 0;  top: 0; bottom: 0px; height: 20px; line-height: 20px; margin: auto 0;'>
				<a style="color: white; text-decoration: none;" href="https://www.facebook.com/v2.5/dialog/oauth?client_id=1682406642074489&amp;state=6241aa28239e903f6cad376e5bc19dd1&amp;response_type=code&amp;sdk=php-sdk-5.4.0&amp;redirect_uri=https%3A%2F%2Fwww.scratchapixel.com%2Ffb-callback.php%3F&amp;scope=email">Sign in</a>			</div>
			
		</div>
	</div>
</div></div>

<body onload="onload();">

<div id='fb-root'></div> <!-- that's required by FB -->
<div class="page-content">
<article><div id='sap-root'></div><!-- that's needed by scratchapixel see onload() --><div class='lesson-title'>Mathematical Foundations of Monte Carlo Methods</div><div class='chapter-table'><div class='chapter-row'><div class='chapter-cell'><b>Contents</b></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="quick-introduction-to-monte-carlo-methods.html">A Quick Introduction to Monte Carlo Methods</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="random-variables-and-probability.html"><b>Random Variables and Probability</b></a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-distribution-part1.html">Probability Distribution: Part 1</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-properties.html">Probability Properties</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="introduction-to-statistics.html">Introduction to Statistics</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="expected-value.html">Expected Value</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="variance-and-standard-deviation.html">Variance and Standard Deviation</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-distribution-part2.html">Probability Distribution: Part 2</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="sampling-distribution.html">Sampling Distribution</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="pdf-and-cdf.html">Probability Density Function (PDF) and Cumulative Distribution Function (CDF)</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="expected-value-of-the-function-of-a-random-variable.html">Expected Value of the Function of a Random Variable: Law of the Unconscious Statistician</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="inverse-transform-sampling-method.html">The Inverse Transform Sampling Method</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="estimators.html">Estimators</a></div></div></div><div class="question">

Statistics and probability are two pretty complex and large topics. Our personal opinion though is that they are very few references or books out there which we believe do explain these fields the right way especially to people who know nothing of the subject. They are either providing tons of pointless examples without explaining the theory, or just give the theory in the form of equations and definitions without really explaining what they mean. We do believe this lesson is one of the best introductions (at least of all the documents we found) on the web so far on probability and statistics. </br></br>

This lesson is not a complete introduction in statistics. This is more a crash course which hopefully provides enough information on the topic for anybody to understand how, why and where statistical methods and probability are used in rendering (particularly with regard to these Monte Carlo methods).
</div>

<h2>Random Variables and Probability</h2>

<p>The first chapter of this lesson will be dedicated to introducing, explaining and understanding what a random variable is. The concept of random variable is central to the probability theory and also to rendering more specifically. What random variables truly is often misunderstood particularly by programmers who just see them as the result of some C++ functions returning some arbitrary number within a given interval. This is not what a random variable is! Let's take an example and start with a coin. Tossing a coin is an example of what we call a <b>random process</b>, because before you toss that coin, you can't tell or predict whether it will land on heads or tails. This is also true of a rolling die, of roulette, of a lottery game, etc. Even though many natural phenomena can be considered as random processes (the rain falling everyday is a random process), we have mostly mentioned examples of games of chance so far, because they are probably what motivated mathematicians to study and develop statistics and probability theory in the first place. Why? Read this:</p>

<div class="scratchquote">The cities of London and Paris were full of shopping opportunities, as well as many chances to lose the family fortune in some high stakes gambling [the <a href="http://www.hyw.com/books/history/Aristocr.htm">text</a> here refers to the life and fortune of aristocrats in the 17th and 18th century]. Games of chance were always popular and the biggest games were found in the larger towns and cities. As a result of all this spending, the nobles [always] needed more money.</div>

<p>In this context, it is not hard to understand why mathematicians of that time got really interested in trying to understand if there was any possible way by which they could measure their chances to win or lose a game of chance, by formalising the process in the form of equations (readers interested in this historical part can search for <a href="http://en.wikipedia.org/wiki/Georges-Louis_Leclerc,_Comte_de_Buffon">Comte de Buffon</a> and <a href="http://en.wikipedia.org/wiki/De_Moivre">de Moivre</a>, etc.). Because heads and tails don't fit well in equations, the first thing they did was to map or assign if you wish, numbers to each possible outcome of a random process. In other words, they said lets assign 1 if the coin lands heads up, and 0 if it lands tails up which you can formalize in mathematical notation as:</p>

$$
X(\omega) = 
\begin{cases}
1, &amp; \text{if} \ \ \omega = \text{heads} ,\\
\\
 0, &amp; \text{if} \ \ \omega = \text{tails} .
\end{cases}
$$

<p>It seems like a very simple idea, but no one had done that before, and this formulation actually is probably more complex than it appears in the first place. The term \(X\) on the left inside is what you call a <b>random variable</b>. Now notice how we actually wrote this term as if we actually had defined it as a function taking the argument \(\omega\). The term \(\omega\) in this context is what we refer to as the <b>outcome</b> of the random process. In our coin example, the outcome can either be "tails" or "heads", in other words a random variable is a real-valued function mapping a possible outcome (heads or tails) from the random process to a number (1 or 0 but note that these numbers don't need to be 1 and 0 they could be anything else you like such as 12 and 23 or 567 and 1027. What you map the outcome of the process to is really up to you). This is very similar in a way to writing something like \(f(x) = 2x + 3\) where \(X(\omega)\) here is similar in a way to \(f(x)\). As you can see, a random variable is not a fixed value. It is more like a function, but the word variable in the name obviously makes things very confusing because the word variable is generally used to denote unknowns in equations. Maybe it would have been best to call that a random function, but random function in probability theory has another meaning, and we have to stick to random variable however always keep in mind that a random variable is not a fixed value, but a function, mapping or associating a unique numerical value to each possible outcome of a random process which is not necessarily a number ("tails", "heads").</p>

<div class="important">
<p>A random variable is a function X(e) that maps the set of experiment outcomes to the set of numbers.</p>
</div>

<div class="captionImage right" style="width: 300px;">
<img class="left" src="../../../images/upload/monte-carlo-methods/coind41d.png?" />
<p class="caption left">Figure 1: the probability of the coin to fall on its heads is 0.5.</p>
</div>

<div class="captionImage right" style="width: 300px;">
<img class="left" src="../../../images/upload/monte-carlo-methods/died41d.png?" />
<p class="caption left">Figure 2: each possible outcome of a six face dice has probability 1/6.</p>
</div>

<p>This is not yet the complete definition of a random variable. The other concept associated to the definition of a random variable is the concept of <b>probability</b>. The coin example is convenient because you don't need to be an expert in statistics to know or intuitively agree with the idea that the chances of either getting "heads" or "tails" when you toss a coin are 50-50 (as we commonly say). And that's because no matter how we throw it in the air, it is not more likely to land on one side or the other. By 50-50 we mean that it is equally likely to land on either "heads" or "tails" (assuming your express chances as a percentage). If you substitute "probability" to "chances" then we can more formally say that the probability of getting either heads or tails is \(1\over 2\) and \(1\over 2\) respectively. The concept of probability is of course very important, because random processes are by definition producing outcomes which are not predictable, however probabilities can be used to describe the chances for a particular event from a random process to occur. And this is greater than we think, because to something that wasn't predictable and thus usable in mathematics, we now have ways of "quantifying" these events (in the form of probabilities) and manipulate these numbers with mathematical tools to do all sort of (useful) things. Applied to the case of a rolling die, the probability of getting either 1, 2, 3, 4, 5 or 6 is \(1\over 6\). Generally the formula to find out the probability of an outcome is 1 divided by the number of possible outcomes (assuming all events are<b> equally likely</b> to happen, which is called <a href="http://en.wikipedia.org/wiki/Equiprobability">equiprobability</a>). In the case of a die, the number of outcomes is 6 (an outcome is any possible results that a random process can produce) thus the probability of either getting 1, 2, ... or 6, any number between 1 and 6, is \(1 \over 6\). </p>

<div class="important">
<p>More generally, we can say that if the outcome of some process must be one of \(n\) different outcomes, and if these \(\scriptsize n\) outcomes are equally likely to occur, then the probability of each outcome is \(1 \over n\).</p>
</div>

<p>Figures 1 and 2 illustrate the way you can represent the probability associated to each outcome of a random process (such as tossing a coin or rolling a die). On the x-axis we write down the possible outcomes of the random process and on the y-axis we write down the probability associated with each one of these outcomes. This is already providing us with a much better definition of a random variable. Not only you can see it as some sort of function mapping outcomes to real values but it also associates a probability value to each one of these outcomes. In others words, \(X\) provides information on the value associated to an outcome of a random process and a value for the probability of that outcome to occur.</p>

<p>Probabilities themselves can be denoted in different ways but often as either \(P\) or \(Pr\). When you see something like this \(\scriptsize Pr(1)\) for instance written in a text book, this means "what is the probability for the experiment's outcome to be 1?". You could also write \(Pr(odd)\) which you could read as "what is the probability for the outcome of the experiment to be an odd number?" etc. Probabilities themseves can be interpreted in two different ways. You can see them as indicating "how strongly" you believe that some event will be true. However if you realised that under some given conditions, some outcome occured 10 times over the 100 times you ran the experiment, then probabilities can also be interepreted as "if you run this experiment 100 times under the same conditions, then you can expect this outcome to occur 10 times". There is quite a few different ways of <a href="http://en.wikipedia.org/wiki/Probability_interpretations">interpreting probabilties</a> but the "evidential" or Bayesian and "physical" probabilities which we just described are the two most common interpretations.</p>

<h2>Terminology</h2>

<p>Terminology in statistics is almost everything. There is so many concepts in probability theory and the differences between them are sometimes so subtle, that given them clear definitions is very important. To paraphrase Wikipedia, in statistics, "confusion results when conventions are not strictly observed". In mathematics, random variables are generally denoted with capital letter such as \(X, Y, .. Z\). The result of a random process is called an <b>observation </b>or also sometimes <b>realizations</b> or <b>observed value</b>. The process of throwing a die for example is a what we call a random process, but the result of that process is what we call an observation, and observations are usually denoted with lower case letters such as \(x, y, ... z\), etc. If a die is rolled \(n\) times the results of the observations are denoted \(x_1, x_2, ..., x_n\). This definition is slightly different from the definition of an <b>event</b>. A set of possible oucomes from an experiment defines what we call an event. For example, we can say that some event occured if the result of a die roll is an odd number (that is either 1, 3 or 5). Finally another important concept related to random variables, is the concept of <b>sample space</b>. A sample space defines the set of all possible outcomes from an experiment. For example, in the case of a die, the sample space is defined as \(S = \{1, 2, 3, 4, 5, 6\}\) (the greek letter \(\Omega\) is sometimes also used but we will stick to \(S\) in this lesson). An event can be seen as a subset of the sample space. For instance, if event A is that an odd number is obtained, then A can be defined as \(\scriptsize A = \{1, 3, 5\}\). Finally each outcome from a set is generally called a <b>member</b> of that set.</p>

<div class="question">
Sample space can either be used to define <a href="http://en.wikipedia.org/wiki/Elementary_event">elementary events</a> or <a href="http://en.wikipedia.org/wiki/Sigma-algebra">non-elementary</a> events. Let's explain. Imagine you have 10 cards labellel and that each card is labelled with the number 0, 1, or 2. Now lets imagine you have 3 cards labelled with 0, 5 cards labelled 1, and 2 cards labelled 2. The sample sample space of non-elementary events is \(\scriptsize S=\{0, 0, 0, 1, 1, 1, 1, 1, 2, 2\}\) and the sample space of elementary events is \(S=\{0, 1, 2\}\).
</div>

<p>When you mean that some event has occurred, you actually potentially mean two things. First that the observation (or outcome from the experiment) satisfies the definition of the event (e.g. if the result of rolling a die is an odd number and the event A is that an odd number is obtained then event A has occurred). And also that the observation which is one of the many possible elements from the sample space, is also an element of that event (if the observation is 3, 3 is an element of subset \(A = \{1, 3, 5\}\)).</p>

<table class='table-basic'>
<tr>
<td style="width: 20%;">
<p>Random Variable</p>
</td>
<td style="text-align:left;">
<p>A random variable is a function X defined from a sample space S (e.g. "heads", "tails") to a measurable space (1, 0). Random variables are denoted with upper case letters.</p>
</td>
</tr>
<tr>
<td style="width: 20%;">
<p>Probability</p>
</td>
<td style="text-align:left;">
<p>A probability provides a quantatative description of the likely occurrence of a particular event.</p>
</td>
</tr>
<tr>
<td>

<p>Observation or Realization</p>

</td>
<td style="text-align:left;">
<p>A realization, or observed value, of a random variable is the value that is actually observed (what actually happened). Realization are denoted with lower case letters (to differenciate them from random variables).</p>
</td>
</tr>
<tr>
<td>
<p>Event</p>
</td>
<td style="text-align:left;">
<p>An event is any collection of outcomes of an experiment. Any subset of the sample space is an event.</p>
</td>
</tr>
<tr>
<td>
<p>Sample Space</p>
</td>
<td style="text-align:left;">
<p>Exhaustive list of all the possible outcomes of an experiment. Each possible result of such experiment is represented by one and only one point in the sample space, which is usually denoted by \(S\). The elements (or members) of the sample space can be thought of as all the different possibilities that could happen.</p>
</td>
</tr>

</table>

<div class="captionImage right" style="width: 300px;">
<img class="left" src="../../../images/upload/monte-carlo-methods/rvdiscretecontinuousd41d.png?" />
<p class="caption left">Figure 3: a random variable can either be discrete or continuous.</p>
</div>

<p>Random variables come in two flavors. They can either be <b>discrete</b> or <b>continuous</b>. When the random variable is discrete, the outcome of the random process can only take a list of exact values. A die roll, a tossed coin, or the number of fishes retained in a net are all example of experiments whose outcome can only be measured by discrete random variables because they produce a <b>finite</b> or <b>countably infinite </b>number of values (the difference between finite and countably infinite is important because although counting how many elements are in a sample space for instance may never finish, each element in that sample space might however be countable and associated with a number). Temperature measurement can be considered as an example of continuous random variable. Why? Because the possible values that an experiment measuring temperature can take, fall on a continuum. Random variables measuring time and distances are also generally of the continuous type.</p>

<p>Because the topic of statistics and probability is already so large, in this lesson we will mostly focused on discrete random variables. Continuous random variables will be studied in the lesson on importance sampling. In the next chapter, we will introduce what is probably the most important concept associated to random variables (and again in this particular lesson only the case of discrete random variables will be considered): the concept of <b>probability distribution</b>. We will then study the properties of probabilities and some concepts associated with them.</p></article></div><!-- end of page-content -->
			<div class='footer-prev-next'>
			<div class='footer-column'><div class='footer-prev-next-row'>
				<div class='footer-prev-next-cell' style='text-align: left;'><p><a href='quick-introduction-to-monte-carlo-methods.html'><i style='float: left;' class='material-icons'>arrow_back</i>Previous Chapter</a></p></div>
				<div class='footer-prev-next-cell' style='text-align: center;'><p>Chapter 2 of  13</p></div>
				<div class='footer-prev-next-cell' style='text-align: right;'><p><a href='probability-distribution-part1.html'>Next Chapter <i style='float: right;' class='material-icons'>arrow_forward</i></a></p></div>
			</div></div>
			</div>

</body>

<!-- Mirrored from www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-mathematical-foundations/random-variables-and-probability by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 01 Aug 2021 17:05:35 GMT -->
</html>