
<!-- 
NEED TO INSERT THE BODY AND ALL THE USEFUL STUFF HERE
-->

<html>

<!-- Mirrored from www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-mathematical-foundations/expected-value-of-the-function-of-a-random-variable by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 01 Aug 2021 17:06:19 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<!-- title should be set at this point in page.php -->
<title>Mathematical Foundations of Monte Carlo Methods (Expected Value of the Function of a Random Variable: Law of the Unconscious Statistician)</title>

<meta name='author' content="Scratchapixel">
<meta name='copyright' content="&copy; 2009-2016 Scratchapixel">
<meta name='keywords' content='Monte Carlo methods, Monte Carlo integration, random variables, probability, statistics, expected value, variance, standard deviation, probability distribution, probability density function, PDF, cumulative distribution function, CDF, inverse transform sampling method, estimator'>
<meta name='date' content='2015-04-18 15:13:02'>

<link rel="stylesheet" type="text/css" href="../../../css/scratchapixel.css"/>
<link rel="stylesheet" type="text/css" href="../../../css/page.css"/>

<link href='../../../../fonts.googleapis.com/css16e1.css?family=Noto+Sans' rel='stylesheet' type='text/css'/>
<link href='../../../../fonts.googleapis.com/css9908.css?family=Open+Sans:700,400,300' rel='stylesheet' type='text/css'/>

<!-- using the material icons from Google http://google.github.io/material-design-icons/ -->
<link rel="stylesheet" href="../../../../fonts.googleapis.com/icone91f.css?family=Material+Icons">

<script type="text/x-mathjax-config">
MathJax.Hub.Config(
	{tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}, 
	displayAlign: "left",
	displayIndent: "1em",
	"HTML-CSS": { scale: 90 },
	jax: ["input/TeX","input/MathML","input/AsciiMath","output/HTML-CSS","output/NativeMML"],
	extensions: ["tex2jax.js","../../../indexf17c.html","../../../indexf17c.html","../../../indexf17c.html","MathZoom.js"],
	TeX: {
		extensions: ["AMSmath.js","../../../indexf17c.html","../../../indexf17c.html","noUndefined.js"]
	}}
);
</script>

<script type="text/javascript" src="../../../../cdn.mathjax.org/mathjax/latest/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript"
	src="../../../scratchapixelSDK.js">
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','../../../../www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-42771397-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- 
https://developers.facebook.com/docs/plugins/share-button/
Include the JavaScript SDK on your page once, ideally right after the opening <body> tag.
-->

<script>
  window.fbAsyncInit = function() {
	FB.init({
	  appId      : '1535346446701691',
	  xfbml      : true,
	  version    : 'v2.1'
	});
  };

  (function(d, s, id){
	 var js, fjs = d.getElementsByTagName(s)[0];
	 if (d.getElementById(id)) {return;}
	 js = d.createElement(s); js.id = id;
	 js.src = "../../../../connect.facebook.net/en_US/sdk.js";
	 fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>

<script>
	!function(d,s,id) {
		var js,fjs=d.getElementsByTagName(s)[0];
		if(!d.getElementById(id)) {
			js=d.createElement(s);js.id=id;
			js.src="../../../../platform.twitter.com/widgets.js";
			fjs.parentNode.insertBefore(js,fjs);
		}
	}(document,"script","twitter-wjs");
</script>


</head>

<style>
.full-page1
{
	position: relative;
	margin: 0; padding: 0; 
	width: 100%; 
	border: 1px solid red;
	color: white;
}

.full-page-header-table1
{
	display: table; 
	width: 100%;
	border: 1px solid orange;
}
</style>

<div style='display: table; width: 100%;'>
	<!-- 
		This should be the content of the top menu bar. So if you want to reuse
		this, just create a table div above and insert the section.
		The height here doesn't mater because it's controlled by the inner table.
-->
<div style='display: table-row;  height: 40px; width: 100%; background-color: #1565C0; color: white;'>
	<!-- we center the cell in the middle of the row -->
	<div style='display: table-cell; width: 100%; border: 1px none orange; vertical-align: middle; text-align: center;'>
		
		<div style='display: inline-block; position: relative; border: 1px none black; width: 670px; margin: 0 auto; padding: 0;'>			
			<!-- 
				This is our logo 
			-->
			<div style='display: inline-block; border: 2px none green;'>
				<span style='font-size: 18px; font-weight: 800;'><a href='../../../indexf17c.html' style='text-decoration: none; color: white;'>Scratchapixel 2.0</a></span>
			</div>
			<!-- 
				This is login 
				The only way you can vertically center stuff here is by forcing the height of the div
				and the eight of the text to be the same
			-->
			<div style='border: 2px none green; position: absolute; right: 0;  top: 0; bottom: 0px; height: 20px; line-height: 20px; margin: auto 0;'>
				<a style="color: white; text-decoration: none;" href="https://www.facebook.com/v2.5/dialog/oauth?client_id=1682406642074489&amp;state=6241aa28239e903f6cad376e5bc19dd1&amp;response_type=code&amp;sdk=php-sdk-5.4.0&amp;redirect_uri=https%3A%2F%2Fwww.scratchapixel.com%2Ffb-callback.php%3F&amp;scope=email">Sign in</a>			</div>
			
		</div>
	</div>
</div></div>

<body onload="onload();">

<div id='fb-root'></div> <!-- that's required by FB -->
<div class="page-content">
<article><div id='sap-root'></div><!-- that's needed by scratchapixel see onload() --><div class='lesson-title'>Mathematical Foundations of Monte Carlo Methods</div><div class='chapter-table'><div class='chapter-row'><div class='chapter-cell'><b>Contents</b></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="quick-introduction-to-monte-carlo-methods.html">A Quick Introduction to Monte Carlo Methods</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="random-variables-and-probability.html">Random Variables and Probability</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-distribution-part1.html">Probability Distribution: Part 1</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-properties.html">Probability Properties</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="introduction-to-statistics.html">Introduction to Statistics</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="expected-value.html">Expected Value</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="variance-and-standard-deviation.html">Variance and Standard Deviation</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="probability-distribution-part2.html">Probability Distribution: Part 2</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="sampling-distribution.html">Sampling Distribution</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="pdf-and-cdf.html">Probability Density Function (PDF) and Cumulative Distribution Function (CDF)</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="expected-value-of-the-function-of-a-random-variable.html"><b>Expected Value of the Function of a Random Variable: Law of the Unconscious Statistician</b></a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="inverse-transform-sampling-method.html">The Inverse Transform Sampling Method</a></div></div><div class='chapter-row'><div class='chapter-cell'><a style='text-decoration: none;' href="estimators.html">Estimators</a></div></div></div><p>In this chapter, we will explain a concept which is very important for Monte Carlo methods. In the chapter on the expected value, we have explained how to compute the expected value of a discrete random variable X. The expected value of X is the sum of each outcome multiplied by its probability (given, as explained in the previous chapter, by the probability mass function or PMF). It can be seen as weighted average:</p>

$$E[X] = \sum_{i=0}^{N-1} X_i pmf(X_i),$$

<p>where N denotes the amount of possible outcomes that the random variable X can take on, and PMF is a probability mass function. It gives the probability of the outcome \(X_i\) to occur. As suggested in the previous chapters, computing this expected value is similar in a way to computing the center of mass of a mobile.</p>

<img class="right" src="../../../images/upload/monte-carlo-methods/centerofmassd41d.png?" />

<p>If we extend this concept to a continuous random variable, we get:</p>

$$E[X] = \int_{-\infty}^{\infty} X pdf(X).$$

<p>This is an important result. Now, let's imagine that you have function f of x: f(x). Let's also imagine that this function is defined over a certain interval of x values. Let's note this interval [a,b]. We now imagine that the variable X is also defined in the interval [a,b]. In other words, each time you draw a number from X, you get some value in the interval [a,b]. The idea here is to use X as the parameter of the function f. In other words, f is a function of the random variable X which we can write as: <b>f(X)</b>.</p>

<p>As a practical example, let's imagine we have a random variable X returning uniformly distributed integers in the interval 1 to 6. Uniformly distributed means that each one of these outcomes have probability 1/6. Now let's imagine we have a function such as:</p>

$$F(X) = (X - 3)^2.$$

<div class="important">
<p>If we draw a random number from X, and that it returns 2, then \(F(X) = (X - 3)^2\), with X = 2, which gives \(F(2) = (2 - 3)^2 = 1\).</p>

<p>What's important to note, is that if X is a random variable then F(X) is also a random variable. If we can't predict the outcome of X then we obviously can't predict the outcome of F(X). Both are random variables, however note also that we can see F(X) as a function transforming X. In other worlds, <b>F(X) is a transformed version of X</b>. You should not assume that F(X) will have the same probability distribution function than X. In other words, the mapping or transform of X, leads to another probability distribution function. Keep in mind these two important ideas:</p>

<ul>
<li>if X is a random variable, any function of X, F(X), will also be random.</li>
<li>X and F(X) have unique probability distribution (unless F(X) = X of course).</li>
</ul>

<p>Note also that if we do know the probability distribution of X before hand, if you wish to know the probability of F(X) you will need to calculate it (we will show how further down).</p>
</div>

<p>Let's get back to our example. So we know that in the case of a uniformly distributed random variable with possible outcome {1, 2, 3, 4, 5, 6}, the probability of each outcome is 1/6. If the function F(X) is defined as \((X - 3)^2\), let's compute the probability distribution of F(X). For each outcome in X, we will need to compute the resulting outcome of F(X). Some of these outcomes will have the same value, thus increasing their probability. According to the multiplication rule, the probability of an outcome is equal to the number of time this outcome is in the set divided by the total possible number of outcomes (which is 6 in our experiment). Let's calculate:</p>

$$
\begin{array}{l}
X = 1, \; F(1) = (1-3)^2 = 4,\\X = 2, \; F(2) = (2-3)^2 = 1, \\ X = 3,\;F(3) = (3-3)^2 = 0, \\ X = 4,\;F(4) = (4-3)^2 = 1, \\X=5,\;F(5) = (5-3)^2 = 4,\\ X = 6,\;F(6) = (6-3)^2 = 9.
\end{array}
$$

<p>As you can see in the table above, computing F(X) for each outcome in X, results in one zero, two ones, two fours and one nine. <b>The probability of an outcome Y from F(X) is equal to the sum of the probability of any of the X for which F(X) = Y</b>. Thus we get:</p>

$$
\begin{array}{l} Pr(F(0)) &=& \dfrac{1}{6}
\\ Pr(F(1)) &=& \dfrac{1}{6} + \dfrac{1}{6} &=& \dfrac{2}{6} 
\\ Pr(F(4)) &=& \dfrac{1}{6} + \dfrac{1}{6} &=& \dfrac{2}{6}
\\ Pr(F(9)) &=& \dfrac{1}{6}.
\end{array}
$$

<p>Now, if we wish to compute the expected value of F(X) we can proceed in two ways. If we know the probability distribution of F(X) we can write (method 1):</p>

$$
\begin{split}
E[F(X)]&=&0 \times Pr(F(X) = 0) + 1 \times Pr(F(X) = 1)  + \\
&&4 \times Pr(F(X) = 4) + 9 \times Pr(F(X) = 9),\\
&=&0 * \dfrac{1}{6} + 1 * \dfrac{2}{6} + 4 * \dfrac{2}{6} + 9 * \dfrac {1}{6},\\
&=&3.167.
\end{split}
$$

<p>Mathematically, if we call Y the random variable F(X) and \(P_Y), the probability distribution of Y, we get:</p>

$$E[F(X)] = E[Y] = \sum Y_i P_Y(Y_i).$$

<p>Where the sum is over all possible values of Y (in our example 4: {0,1,4,9}).</p>

<p>Or if you don't know the probability distribution of F(X), you can still use your knowledge of the probability distribution of X to calculate E[Y] (method 2):</p>

$$
\begin{split}
E[F(X)] & = &(1-3)^2\times Pr(X = 1) + (2-3)^2\times Pr(X = 2) +\\
&& (3-3)^2\times Pr(X = 3)+ (4-3)^2\times Pr(X = 4) +\\
&& (5-3)^2\times Pr(X = 5) + (6-3)^2\times Pr(X = 6)\\
&=&4 * \dfrac{1}{6} + 1 * \dfrac{1}{6} + 0 * \dfrac{1}{6} + 1 * \dfrac{1}{6} + 4 * \dfrac{1}{6} + 4 * \dfrac{1}{6} \\
&=&3.167.
\end{split}
$$

<p>Mathematically we would write this result as:</p>

$$E[F(X)] = F[Y] = \sum F(X_i) P_X(X_i).$$

<p>Where the sum is over all possible values of X (in our example 6: {0,1,2,3,4,5,6}).</p>

<p>This in an important result because,<b> in practice, you don't necessarily know the probability distribution of F(X). Of course you can calculate it, but this is an extra step, which you can avoid if you use the second method</b>. Mathematically, this result can be written as:</p>

<div class="important">
$$E[F(X)] = \sum F(X) P_X(X),$$

<p>for a discrete random variable, and:</p>

$$E[F(X)] = \int F(X) P_X(X) \:dX,$$

<p>for continuous random variables. These equation are very important and play an essential role in Monte Carlo methods. In mathematics, they are sometimes refer to as the <b>law of the unconscious statistician</b>. We are not too sure why, but the common explanation is that in fact, most people don't realize that when they compute something such as the expected value of the function of a random variable, rather than using the first solution to compute E[F(X)] (where we use the probability distribution of F(X)), we actually use the second solution (where we use the probability distribution of X):</p>

<p>When the statistician thinks he/she computes: \(E[Y] = \sum Y_i P_Y(Y_i)\), what he/she often computes is actually \(E[F(X)] = \sum X_i P_X(Y_i)\). While obviously the result is the same, one requires the probability distribution of F(X) when the second doesn't. </p>

<p>Keep in mind that the beauty of the method is that <b>it is not necessary to know  the probability distribution of F(X) to compute its expected value, as long as you know the probability distribution of X.</b></p>
</div>

<p>This result is the foundation of <b>Monte Carlo integration</b> [link].</p></article></div><!-- end of page-content -->
			<div class='footer-prev-next'>
			<div class='footer-column'><div class='footer-prev-next-row'>
				<div class='footer-prev-next-cell' style='text-align: left;'><p><a href='pdf-and-cdf.html'><i style='float: left;' class='material-icons'>arrow_back</i>Previous Chapter</a></p></div>
				<div class='footer-prev-next-cell' style='text-align: center;'><p>Chapter 11 of  13</p></div>
				<div class='footer-prev-next-cell' style='text-align: right;'><p><a href='inverse-transform-sampling-method.html'>Next Chapter <i style='float: right;' class='material-icons'>arrow_forward</i></a></p></div>
			</div></div>
			</div>

</body>

<!-- Mirrored from www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-mathematical-foundations/expected-value-of-the-function-of-a-random-variable by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 01 Aug 2021 17:06:23 GMT -->
</html>