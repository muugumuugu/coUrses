<html>
<head>
<link rel=StyleSheet href="../../pdbstyle.css" type="text/css" media=all>
<title>3D Reconstruction of a human body</title>
</head>
<body>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<script language="JavaScript">
<!--
   if (self.location.href != top.location.href) {
      top.location.href = self.location.href;
   }
-->
</script>


<center><table width=800><tr><td>

<center>
<h1>3D Reconstruction of a human body</h1>
See <a href="../humanscan/index.html">original test subject</a><p>
Software: MetashapePro and custom tools to control cameras<br>
Written by <a href="../index.html">Paul Bourke</a><br>
August 2019<p>
Translation into <a href="http://paulbourke.net/reconstruction/humanscan2/index_ge.html">Georgian</a> by Ana Mirilashvili.<br>
Translation into <a href="http://paulbourke.net/reconstruction/humanscan2/index_bu.html">Bulgarian</a> by Zlatan Dimitrov.<br>
<!--
Translation into <a href="index_ab.html">Azerbaijanian</a> by Amir Abbasov</a>
-->
Translation into <a href="https://prodocs24.com/articles/3d-reconstruction-of-a-human-body/">
Azerbaijanian</a> by Amir Abbasov</a>
</center><p><br><p>

<p align="justify">
The following is a report on the construction of a rig to capture photographs
with the intent of using standard reconstruction software to create 3D human
models. The application is the capture of athletes, namely swimmers, and as such
one cannot rely on sufficient feature points on the subject.
The initial approach was to paint the subjects in such a way so as to ensure
sufficient feature points. This previous <a href="../humanscan/index.html">evaluation exercise</a>
was a test to both
determine the best painting pattern, as well as determine the number of cameras
required.
</p>

<p align="justify">
Unlike the 3D reconstruction of inanimate objects, a human cannot reasonably stay
still for more than a second or two. The more traditional 3D reconstruction with a
single camera would require at least ten minutes, hence the use of a mannequin
for the earlier <a href="../humanscan/index.html">testing</a>. The solution then is to deploy
multiple cameras that will be simultaneously triggered. Genlock is not required, the
system as designed triggers the cameras to within 1/10 second, easily sufficient to
avoid any movement for a subject who is told to stay as still as possible.
</p>

<p align="justify">
The first build of the system is as follows.
</p>

<center>
	<a href="http://paulbourke.net/reconstruction/humanscan2/rig.jpg"><img src="http://paulbourke.net/reconstruction/humanscan2/rig_s.jpg" width=800 height=600 border=1></a><br>
</center><p><br><p>

<center>
   <img src="http://paulbourke.net/reconstruction/humanscan2/image4.jpg" width=800 height=1265 border=0></a><br>
</center><p><br><p>

<b>System specifications</b><p>

<center>
<table>
<tr><td>Number of cameras</td><td width=20>&nbsp;</td><td>48 (4 x 12 cylindrical grid)</td></tr>
<tr><td>Camera resolution</td><td width=20>&nbsp;</td><td>24 MPixels each</td></tr>
<tr><td>Lens</td><td width=20>&nbsp;</td><td>18 mm</td></tr>
<tr><td>Radius, height</td><td width=20>&nbsp;</td><td>3.5m, 3.0m</td></tr>
<tr><td>Connectivity</td><td width=20>&nbsp;</td><td>Camera trigger, global contact closure</td></tr>
<tr><td>&nbsp;</td><td width=20>&nbsp;</td><td>USB via 3x20 port USB hubs</td></tr>
<tr><td>Computer OS</td><td width=20>&nbsp;</td><td>MacPro, Mojave</td></tr>
</table>
</center>
<p>

<b>Capture and processing pipeline</b><p>

<p align="justify">
The typical capture sequence starts by taking a photographic set of a suitably texture rich
calibration object. This serves to create accurate positions and
orientations of the cameras.
</p>

<center>
	<img src="http://paulbourke.net/reconstruction/humanscan2/image1.jpg" width=800 height=505 border=1>
</center><p>

<p align="justify">
The second photographic set is a photograph of the space without any subjects,
this is used to create masks for subsequent captures with the subject.
The following shows a subsequent capture with the outline in white of the
mask formed by simply subtracting the empty space image from the subject space image.
This is obviously done per camera for a camera specific masking.
Note: the cameras are in portrait mode.
</p>

<center>
   <img src="http://paulbourke.net/reconstruction/humanscan2/image2.jpg" width=800 height=722 border=1>
</center><p>

<p align="justify">
Resulting reconstructed 3D model as plain mesh and textured mesh.
Depth maps shown also for each camera view.
</p>

<center>
   <img src="http://paulbourke.net/reconstruction/humanscan2/image3.jpg" width=800 height=730 border=1>
</center><p>

<p align="justify">
While there are a few things yet to do to improve geometric quality from the automatic
processes, there is still expected to be some manual cleaning. In this case closing off the
soles of the feet, removing partial glasses (clear glass is not likely to reconstruct
through a photographic process) and smoothing rough surfaces.
</p>

<center>
   <img src="http://paulbourke.net/reconstruction/humanscan2/image5.jpg" width=800 height=711 border=1>
</center><p>

<p align="justify">
Some further test subjects from the installation and testing phase.
</p>

<center>
   <a href="http://paulbourke.net/reconstruction/humanscan2/models.png"><img src="http://paulbourke.net/reconstruction/humanscan2/models_s.png" width=800 height=320 border=1></a><br>
</center>
<p>

<b>Models on Sketchfab</b><p>
<ul>
<li><a href="https://skfb.ly/6MRGP">Stance 1</a><br>
<li><a href="https://skfb.ly/6MRGL">Stance 2</a><p>
</ul>
<p>

</td></tr></table></center>
</body>
</html>

