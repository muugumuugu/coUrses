<html>
<head>
<link rel=StyleSheet href="../../pdbstyle.css" type="text/css" media=all>
<title>Photomosaics for high resolution image capture</title>
</head>
<body>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<script language="JavaScript">
<!--
   if (self.location.href != top.location.href) {
      top.location.href = self.location.href;
   }
-->
</script>


<center><table width=800><tr><td>

<center>
<h1>Photomosaics for high resolution image capture</h1>
Written by <a href="../index.html">Paul Bourke</a><br>
April 2014<p>
Translation into <a href="http://paulbourke.net/miscellaneous/photomosaic/index_se.html">Swedish</a> by Eric Karlsson.<br>
</center><p>

<b>Introduction</b><p>
<p align="justify">
The following will present so called "photomosaics", although in general there is some
confusion with the terminology. Photo collages, photo mosaics, image mosaics, gigapixel photographs,
panorama photography, etc. Gigapixel and panorama photography assume the camera is
rotated about its nodal point, indeed great care is often taken by the photographer
to achieve this in order to minimise
stitching/blending artefacts arising from parallax errors. Examples of wide angle panoramas are
shown in figure 1 and 2. There are a number of reasons for capturing and composing images
such as these, the ultra high resolution panoramas stores, in one image, both the detail
when zooming in and the context, zooming out. The 360x180 bubble photograph example
in figure 2 are often used to give one
the sense of a place, everything visible from the camera position is recorded and sometimes 
this can additionally be at very high resolution. These are often called spherical panoramas
or more formally equirectangular projections.
</p>

<center>
<img src="http://paulbourke.net/miscellaneous/photomosaic/figure1s.jpg" width=800 height=384 border=0><br>
<smalltext>
Figure 1. Traditional high resolution panorama (Beacon Island).</smalltext>
</center><p>

<p align="justify">
The resolution of these panoramas is a function of the number of photographs taken, this
in turn is often limited by the field of view (FOV) of the lens and for dynamic scenes the
time required for a large number of photographs. Each photograph overlaps with its neighbours
and feature points between pairs of photographs are used to finally stitch and blend the
individual photographs together.
</p>

<center>
<img src="http://paulbourke.net/miscellaneous/photomosaic/figure2s.jpg" width=800 height=400 border=0><br>
<smalltext>
Figure 2. 360 x 180 degree "bubble".
</smalltext>
</center><p>

<b>Photomosaics</b><p>

<p align="justify">
In what follows the term photomosaic is taken to refer to an image made up of 
a number of smaller
photographs where the camera position varies.
Strictly speaking, a photomosaic cannot be perfect except for planar objects.
An example of capturing a photomosaic of a planar object
is given in figure 3, the image presented is created from a 8x8 grid of
photographs taken with a 20MPixels camera and 100mm lens. The resolution of the final image is a
function of the field of view of the lens, a narrower FOV means more photographs can
be taken. The same feature point detection and stitching that is used for panoramas
is deployed in this and subsequent cases.
</p>

<center>
<img src="http://paulbourke.net/miscellaneous/photomosaic/figure3s.jpg" width=800 height=421 border=0><br>
<smalltext>
Figure 3. Aboriginal dot painting.<br>
</smalltext>
</center><p>

<b>Fundamental limitation</b><p>

<p align="justify">
The reason why a perfect stitch as shown in figure 3 cannot be achieved for a scene where
there are objects at different depths, consider the situation in figure 4. This shows the side view
of two cameras positions with a blue sphere and red cube at different depths in the overlap zone.
It is clear that it is not possible to seamlessly blend these two images together.
</p>

<center>
<img src="http://paulbourke.net/miscellaneous/photomosaic/figure4s.jpg" width=500 height=588 border=0><br>
<smalltext>
Figure 4. Fundamental limitation.
</smalltext>
</center><p>

<p align="justify">
Note that it is possible to blend two images such as the ones illustrated in figure 4 for
any particular depth, just not all depths at once. 
The situation improves for very narrow FOV lenses which increasingly approximates a parallel
projection.
</p>

<p align="justify">
This is a well known effect for multiple 
camera video rigs for example, such as the various GoPro rigs and LadyBug series of cameras.
While every attempt is made to locate the nodal point of the cameras as close together as
possible, this parallax error still exists to some extent and fundamentally limits the 
stitching quality. Figure 5 shows an example from the LadyBug camera with two blend zones enlarged,
the one on the left is at the selected blending distance, the lower right is a closer object
with the corresponding blend errors.
</p>

<center>
<img src="http://paulbourke.net/miscellaneous/photomosaic/figure5s.jpg" width=800 height=789 border=0<br>
<smalltext>
Figure 5. Stitching errors in LadyBug video footage.
</smalltext>
</center><p>

<p align="justify">
All is not lost, in many application there are still benefits in being able to map
a large area despite errors in the stitching. The feature point detection and stitching/blending
will warp the images in the face of these parallax errors. What one loses is any ability
to reliably measure distances and angles, the image warping can be arbitrary in the algorithms
attempt to join matched feature points.
</p>

<b>Examples</b><p>

<p align="justify">
In the following examples the camera is moved significantly between photographs,
indeed in all cases some attempt was made to move the camera perpendicular to the
scene surface.
In each, the warping required to match the shared feature points in the photographs is evident.
Figure 6 demonstrates the ability of the feature point detection algorithm to be
less sensitive to colour information, the photographs here are scans from black and white
(greyscale) slides.
</p>

<center>
<a href="http://paulbourke.net/miscellaneous/photomosaic/figure6.jpg">
<img src="http://paulbourke.net/miscellaneous/photomosaic/figure6s.jpg" width=800 height=300 border=0></a><br>
<smalltext>
Figure 6. Photomosaic from the Batavia shipwreck, photographs from 1972.
</smalltext>
</center><p>

<p align="justify">
Figure 7 clearly illustrates the discontinuities than can arise from objects
at different depths, for example the yellow and black framing which shows
discontinuities as the software has preferred to match the deeper decking.
</p>

<center>
<a href="http://paulbourke.net/miscellaneous/photomosaic/figure7.jpg"><img src="http://paulbourke.net/miscellaneous/photomosaic/figure7s.jpg" width=800 height=346 border=0></a><br>
<smalltext>
Figure 7. 23 photographs of the Clarence ship wreck. 
Exhibits many errors due to moving camera and reasonable depth range for the objects of interest.
</smalltext>
</center><p>

<p align="justify">

</p>

<center>
<img src="http://paulbourke.net/miscellaneous/photomosaic/figure8s.jpg" width=800 height=439 border=0></a><br>
<smalltext>
Figure 8. Photomosaic in geoscience, 15 photographs along a fault line feature.
</smalltext>
</center><p>


</td></tr></table></center>
</body>
</html>
