<html>
<head>
<link rel=StyleSheet href="../../pdbstyle.css" type="text/css" media=all>
<title>Notes on Resolution</title>
</head>
<body>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<script language="JavaScript">
<!--
   if (self.location.href != top.location.href) {
      top.location.href = self.location.href;
   }
-->
</script>


<center><table width=800><tr><td>

<center>
<h1>Tiled Displays</h1>
Written by <a href="../index.html">Paul Bourke</a><br>
September 2009, <a href="index.html#2013">Update: May 2013</a><p>
</center>
<p><br><p>

<p align="justify">
The following discusses the relative merits of tiling conventional displays in order
to achieve a high resolution display. The main use of such displays in visualisation
is to be able to see detail as well as the big picture. On a lower resolution display
one is required to zoom in to see the detail at which point the context is lost.
Similarly, when the whole image is visible the detail is smaller than a single pixel
and thus lost.
</p>

<p align="justify">
An intentional design criteria in the installation discussed here was the use of a
single computer in order to maximise the support across commercially available software,
at the cost of performance compared to using a cluster. This can be partly justified
by the expectation of increased graphics performance in time.
</p>

<center>
	<img src="http://paulbourke.net/miscellaneous/resolution/plans.jpg" width=800 height=607 border=0>
</center><p>

<p align="justify">
The design is based upon the Apple or DELL 30 inch displays, each one 2560x1600 pixel
resolution, the highest on the market at the time. The displays are from the same factory,
unfortunately the frame is about the same thickness for both and cannot readily be
removed. The DELL displays were chosen simply because of the dark frame vs the lighter
frame for the Apple version.
The maximum number of dual pipe dual link
DVI graphics cards that could be installed in the machine of choice (Apple Mac Pro) was 4,
in other words 8 displays. The 2x4 arrangement with the panels on their sides gives the
most convenient aspect ratio of 5:4 (6400 x 5120).
</p>

<center>
<table><tr><td>
	<a href="http://paulbourke.net/miscellaneous/resolution/display1.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/display1_s.jpg" width=400 height=604 border=1></a>
</td><td>
	&nbsp;
</td><td>
	<a href="http://paulbourke.net/miscellaneous/resolution/display2.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/display2_s.jpg" width=400 height=604 border=1></a>
</td></tr></table>
</center><p>

<p align="justify">
While the gaps between each frame is an obvious disadvantage, in order to achieve the
raw pixel resolution it is more cost effective than using tiled data projectors. Not only
is there the cost benefit but also the software complexity dealing with edge blending between
tiled projector displays (assuming a seamless display is the target).
It should be noted that these 30 inch monitors at 2560x1600 pixels have almost twice the
pixels of a HD projector (2560x1600 compared to 1920x1080).
</p>

<center>
	<a href="http://paulbourke.net/miscellaneous/resolution/hubble3.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/hubble3_s.jpg" width=800 height=600 border=1></a>
</center><p>

<p align="justify">
The colour depth of these displays would seem to be better than what one can
achieve with data projectors, this includes the black levels.
The first two images are fresh from the repaired Hubble Space Telescope, these first
offerings at the time of writing were in the range of 3K and 4K square. The total
resolution of the display is 4*1600 pixels horizontally by 2*2560 pixels vertically,
a total of 6400 by 5120 (32MPixels).
</p>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/hubble2.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/hubble2_s.jpg" width=800 height=600 border=1></a>
</center><p>

<p align="justify">
The following image is a high definition photograph of the Boolardy station in West
Australia and the site of the ASKAP (Australia Square Kilometer Array Pathfinder), the
site of the proposed SKA. The image is 32,000 by 32,000 pixels.
</p>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/boolardy.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/boolardy_s.jpg" width=800 height=600 border=1></a>
</center><p>

<p align="justify">
An example of a tiling of high resolution images, courtesy of Florian Fusseis.
Notice the second display from the top left is a different colour, this is due to
it being a replacement screen where the displays were originally a running sequence of serial
numbers. Colour space adjustments on the panels have subsequently been made to create
consistent colours across all panels.
</p>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/geology1.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/geology1_s.jpg" width=800 height=600 border=1></a>
</center><p>

<p align="justify">
A further example from the recent high resolution images from the Hubble Space Telescope.
</p>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/hubble1.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/hubble1_s.jpg" width=800 height=600 border=1></a>
</center><p>

<p align="justify">
The above were all using standard Mac applications (eg: PhotoShop and Preview), the
main issue with this is the inability to take account of the gaps between the displays
giving quite an unnatural sensation as one tracks content between displays.
A particularly elegant way to deal with this is the Quartz Visualiser.
The following example uses a Quartz Composer composition to display the image,
allow the user to scale, pan, and rotate. Quartz Visualiser then takes that are handles
the image across the tiled display and automatically adjusts for a user specified interdisplay
gap. While perhaps not evident here, the way the image disappears behind the frames
between the display area results in a much more believable result, not surprising
perhaps since we are accustomed to viewing scenery through frames windows. The only
slight complication is that Quartz Visualiser ignores mouse and keyboard IO, this simply
means a separate QC composition is created that runs on a separate computer and controls
the translation, zooming, and rotation through a network patch. The two QC compositions
<a href="http://paulbourke.net/miscellaneous/resolution/qc.zip">are provided</a> to give an idea of how this is achieved.
</p>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/gaps1.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/gaps1s.jpg" width=800 height=530 border=1></a>
</center><p>


<p align="justify">
At the time of writing (Snow Leopard 10.6.1) seems to have a number of bugs when
it comes to supporting this number of displays. Serious bugs such as the display
preferences for arranging the displays runs very slowly and often fails to display
the panels at all.
</p>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/simulation.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/simulation_s.jpg" width=800 height=600 border=1></a>
</center><p>
<p align="justify">
Application to interactive viewing of cosmological simulation data, 15 million points.
</p>

<b>Update, August 2010</b><p>
<p align="justify">
The display has been upgraded from a single Mac with 4 graphics cards to a single
MSWindows (and Linux) box with a pair of nVidia Quadraplex units. These, in SLI mode
present a single large canvas to any application. The result is a considerable
increase in performance while retaining the desired ability to run any software.
</p>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/australia.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/australia_s.jpg" width=800 height=600 border=1></a><br>
	<smalltext>Australia</smalltext>
</center><p>

<p align="justify">
The nVidia drivers take care of the bezel width and in the latest version (at the time of
writing) just started supporting portrait mode. 
</p>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/perth.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/perth_s.jpg" width=800 height=600 border=1></a><br>
	<smalletxt>Perth City</smalltext>
</center><p>

<p align="justify">
This is different to the Google "Liquid Galaxy" on a few points.
</p>
<ul>
<li><p align="justify">The Liquid Galaxy is "only" 16MPixels whereas this is 33MPixels.</p>
<li><p align="justify">These panels are aligned flat rather than curved around the
users. The curved approach gives a more immersive feeling, this display was targeted
more at data visualisation.</p>
<li><p align="justify">The approach used here is certainly simpler but, depending on what
is spent on each Linux box, probably a bit more expensive due to the QuadraPlex boxes.</p>
<li><p align="justify">As with the OptiPortal system, the Liquid Galaxy is limited in the
software it can support.</p>
</ul>

<center>
   <a href="http://paulbourke.net/miscellaneous/resolution/sample5.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/sample5_s.jpg" width=800 height=600 border=1></a><br>
	<smalltext>Mt Cook, New Zealand</smalltext>
</center><p>


<b>Configuration</b><p>

<p align="justify">
At the time of writing (February 2011), 
the nVidia drivers leave a lot to be desired. They don't "naturally"
support portrait mode, the work-around is set SLI as a 4x2 landscape and then switch to
portrait in the MS display preferences. 
</p>

<center>
<img src="http://paulbourke.net/miscellaneous/resolution/screen1.png" width=600 height=522 border=0><p>
<img src="http://paulbourke.net/miscellaneous/resolution/screen2.png" width=800 height=605 border=0><p>
</center>

<a name="googleart"><b>Google Art Project</b><p></a>
<center><table><tr><td>
	<a href="http://paulbourke.net/miscellaneous/resolution/ambassador1.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/ambassador1s.jpg" width=400 height=300 border=1></a><br>
	6400 x 5000 pixels
</td><td>
   <a href="http://paulbourke.net/miscellaneous/resolution/ambassadorx2.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/ambassadorx4s.jpg" width=400 height=300 border=1></a><br>
	Approximately 12000 x 10000 pixels across the whole image
</td></tr><tr><td>
   <a href="http://paulbourke.net/miscellaneous/resolution/ambassadorx4.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/ambassadorx4s.jpg" width=400 height=300 border=1></a><br>
	Approximately 24000 x 20000 pixels across the whole image
</td><td>
   <a href="http://paulbourke.net/miscellaneous/resolution/ambassadorx16.jpg"><img src="http://paulbourke.net/miscellaneous/resolution/ambassadorx16s.jpg" width=400 height=300 border=1></a><br>
	Approximately 100000 x 80000 pixels across the whole image
</td></tr></table></center><p>

<br><br>
<a name="2013">
<b>Update: May 2013</b></a><p>

<p align="justify">
This display is made up from lower resolution (just HD, 1920x1080) panels, the
obvious difference is the small size of the bezels. Rated at 5.5mm pixel to pixel, in reality it is more like 7mm. The panels used here are from Samsung, each 46 inches diagonal,
that is just over 1m wide. The array comes ready to assemble in almost any desired
configuration.
</p>
<center>
	<img src="http://paulbourke.net/miscellaneous/resolution/samsung1.jpg" width=800 height=600 border=0>
</center><p>

<p align="justify">
Sales pitch: "<i>Such displays can be beneficial when studying high resolution datasets, typically images or high 
density 2D and 3D graphics. The large number of available pixels allows one to see more of the data thus 
reducing the need to pan and zoom. The larger physical scale of the display also facilitates collaborative 
use by more than one person, compared to a single small display.</i>" 
</p>

<center>
   <img src="http://paulbourke.net/miscellaneous/resolution/samsung2.jpg" width=800 height=600 border=0>
</center><p>

<center>
   <img src="http://paulbourke.net/miscellaneous/resolution/samsung3.jpg" width=800 height=600 border=0>
</center><p>

<p align="justify">
As before, this is driven by a single computer, in this case a FirePro W9000.
The unique feature of this card are the 6 DisplayPort outputs allowing one
to drive the 6 displays directly. Of course this installation is only about
12 MPixels, much less than the previous version. 
</p>

<center>
   <img src="http://paulbourke.net/miscellaneous/resolution/samsung4.jpg" width=800 height=600 border=0>
</center><p>

<center>
   <img src="http://paulbourke.net/miscellaneous/resolution/samsung5.jpg" width=800 height=600 border=0>
</center><p>

<p align="justify">
AMD control panel shown below, called the "Catalyst Pro Control Centre". 
Certainly a significantly more stable and elegant interface than the nVidia
driver control panels.
</p>
<center>
	<img src="http://paulbourke.net/miscellaneous/resolution/AMD.png" width=800 height=762 border=0>
</center><p>

<br><br>


<center>
<h1>Display resolution</h1>
Written by <a href="../index.html">Paul Bourke</a><br>
March 2014
</center>
<p><p>

<p align="justify">
The following will present the relative resolution of different displays. A relatively straight forward
exercise but as a frequently asked question it warrants some consideration.
The first thing to realise is the perceived resolution is not just about the technical
resolution of the display or projector.
It also depends on the size of the display and the distance of the viewer.
The best measure of the perceived resolution 
is the angle a pixel subtends at the eye, so for a device with a certain
number of pixels the perceived resolution increases as the device becomes smaller or as
the viewer get closer. In what follows it will be assumed the pixels are square, the vast majority
of the cases these days, this allows us to only consider the horizontal angle
a pixel subtends at the eye, the vertical angle will be the same.
It should be noted that the discussion here assumes a perfect device displaying content
with independent pixels, this is rarely the case (see later for degrading effects).
</p>

<p align="justify">
If N is the number of horizontal pixels, W the physical width of the display or
projected image, and D the distance the viewer is from the display, then the angle A in radians
of a single pixel subtended at the eye is simply
</p>
<center>
A = W / (N D)
</center><p>

<p align="justify">
The following table gives some representative subtended angles for commonly encountered
display panels or projected images.
</p>

<table border=1 width=100% cellpadding=4 cellspacing=0>
<tr><td>
<b>Description</b>
</td><td>
<center><b>Angle a pixel subtends<br>at the eye (degrees)</b></center>
</td></tr>

<tr><td>
Occulus kit V2, 440 pixels per inch panel viewed from 4cm.
</td><td align="center">
0.16
</td></tr>

<tr><td>
30 inch display (660mm wide) with 2560 pixels viewed from 400mm.
</td><td align="center">
0.07
</td></tr>

<tr><td>
VGA (1024x768) projector at 3m wide at 5m viewing distance, typical PPT presentation system.
</td><td align="center"> 
0.067
</td></tr>

<tr><td>
iPhone 4 (326 pixels per inch) viewed from 200mm.
</td><td align="center">
0.065
</td></tr>

<tr><td>
400mm wide HD (1920x1080) computer display viewed from 400mm.
</td><td align="center">
0.06
</td></tr>

<tr><td>
iPad retina display (264 pixels per inch) viewed from 300mm
</td><td align="center">
0.036
</td></tr>

<tr><td>
Typical tiled display, 46inch (1m wide) HD panels viewed from 2m.
</td><td align="center">
0.03
</td></tr>

<tr><td>
2m wide HD (1920x1080) home cinema viewed from 5m.
</td><td align="center">
0.02
</td></tr>

<tr><td>
Typical home LCD, 42inch (910mm) HD panel viewed from 4m.
</td><td align="center">
0.018
</td></tr>

<tr><td>
2m wide 4K projector viewed from 5m.
</td><td align="center">
0.01
</td></tr>

<tr><td>
Digital 4K iMAX on a 10m screen viewed from 25m.
</td><td align="center">
0.01
</td></tr>

</table>
<p>

<p align="justify">
What might ask what the resolving power of the human eye is, there is not one definition.
20/20 vision is defined as the ability to resolve two points of light separated by a
visual angle of 0.016 degrees.
Alternatively the maximum angular resolution of the human eye at a distance of 1 km is
typically 30 to 60cm, this gives an angular resolution of between 0.02 to 0.03 degrees.
</p>

<p align="justify">
It should be noted that the above considerations relate to the idealised situation, in
reality the actual perceived resolution of a digital image presentation can be less. Some factors reducing the
effective resolution are listed below.
</p>

<ul>
<li><p align="justify">
The lens quality of a projector based display.
</p>
<li><p align="justify">
The screen door effect around pixels of a display panel or projector.
</p>
<li><p align="justify">
Lossy compression of the digital movies being presented, most notably compression
such as mpg, H264, and similar. To a lesser extent lossy compression of image
formats such as JPEG.
</p>
<li><p align="justify">
For projected images the projection surface can degrade the image quality.
Similarly for panels the layers of transparent glass/plexiglass in front of the
raw pixels diffuse/scatter some light.
</p>
</ul>

<center>
<a href="http://paulbourke.net/miscellaneous/resolution/angles.png"><img src="http://paulbourke.net/miscellaneous/resolution/angles_s.png" width=800 height=589 border=0></a>
</center><p>
<smalltext>
Angles marked on a figure from <b>PQM: A New Quantitative Tool
for Evaluating Display Design Options</b>.
Software, Electronics, and Mechanical Systems Laboratory 3M Optical Systems Division
Jennifer F. Schumacher, John Van Derlofske, Brian Stankiewicz, Dave Lamb, Art Lathrop.
</smalltext>
<p>

<b>Planetariums domes</b><p>

<p align="justify">
One might extend this to planetariums although in this case the true resolution is
influenced by other things. In what follows it will be assumed that the rated dome 
projection is real where in fact it is not, for example the use of the words "4K" and
"8k" to refer to dome resolution have no meaning in reality but are purely marketing terms.
This is due to the following factors.
</p>
<ul>
<li><p align="justify">
<p align="justify">How much edge blending is there? Any edge blending can drastically reduce the resolution 
across the blend, especially as components drift.
</p>
<li><p align="justify">
Planetariums with multiple projectors
have image warping (geometry correction) occurring so pixels are no longer independent.
</p>
<li><p align="justify">
There are lenses on the projectors with blurring and chromatic error effects increasing towards
the rim of the lens, especially so for wide angle or fisheye lenses.
</p>
<li><p align="justify">
As mentioned before most, if not all, movie playback in planetariums is done using
very lossy codecs, such as mpeg and its variants. As such there is significant degradation
occurring that again removes any pixel independence, indeed adds even nastier long range effects.
</p>
</ul>

<p align="justify">
In the following table it is assumed that the observer is in the center of the dome
and located at the spring line (the ideal viewing position). For viewers off center
the angle a pixel subtends at the eye increases for the most distant side of the dome
and decreases for the close side. Note that in the scenario discussed here the radius
of the dome is not a factor, on a larger dome the pixels are larger but further away so the
perceived resolution remains the same.
</p>

<table border=1 width=100% cellpadding=4 cellspacing=0>
<tr><td>
<b>Description</b>
</td><td>
<center><b>Angle a pixel subtends<br>at the eye (degrees)</b></center>
</td></tr>

<tr><td>
4K planetarium
</td><td>
<center>0.06</center>
</td></tr>

<tr><td>
8K planetarium
</td><td>
<center>0.03</center>
</td></tr>

</table><p>

<br>

<center>
<h3>Comparative resolution of 360 video capture devices</h1>
<a href="../index.html">Paul Bourke</a><br>
October 2014
</center>
<p><br><p>

<b>Introduction</b><p>

<p align="justify">
360 degree video capture has a long history but with a renewed interest in immersive displays
and in particular commodity head mounted displays such as the Oculus, the question is often
asked how does one capture video at sufficient resolution. Indeed, what is sufficient
resolution? The following will provide one way to evaluate the resolution of various 360
degree video capture devices. It should be pointed out that while an idealised capture
system will be considered, that is in practice far from the reality. Some of the factors
that further degrade the actual capture quality are listed at the end of this document.
</p>

<p align="justify">
One way to evaluate what resolution one needs is to consider the size of a pixel on the
final 360 video frame and what area that covers in the scene. In what follows only resolution
in the horizontal axis will be considered, that is, cylindrical projections. Similar arguments
can be extended vertically for cameras that capture spherical projections such as the LadyBug
range.
</p>

<p align="justify">
Imagine a camera that captures cylindrical or spherical
projections with N pixels across, these pixels are spread around the
360 degrees and therefore a single pixels subtends 360/N degrees. One can then project this
angle into the world and compute the size of the pixel at different ranges R. The width of
a pixel W at range R is then simply:
</p>
<center>
W = 2 pi R / N 
</center><p>

<p align="justify">
This then provides an upper limit on the resolving ability for a camera that results in N
pixel across 360 degrees. This assumes perfect optics, no sensor noise, no image compression, no 
multiple camera blending/stitching 
and a raft of other effect that will limit the effective resolution.
</p>

<b>Examples</b><p>
<p align="justfy">
In the following table the pixel width at 2m, 5m and 20m are presented for various 360 camera
solutions. Please note that the optimal resolution of some of these devices is a "best guess" or
based upon manufacturers specifications (often dubious). 
</p>
<center><table width=100% cellspacing=0  cellpadding=5 border=1>
<tr><td>&nbsp;
</td><td><b>Estimated resolution</b>
</td><td colspan=3><center><b>Pixel width W at</b></center>
</td><td>&nbsp;
</td></tr>

<tr><td><b>Device</b>
</td><td><b>N</b>
</td><td><b>2m</b>
</td><td><b>5m</b>
</td><td><b>20m</b>
</td><td><b>Comments</b>
</td></tr>

<tr><td>LadyBug-3
</td><td>5400
</td><td>2 mm
</td><td>6 mm
</td><td>23 mm
</td><td>16 fps at this resolution.<br>Spherical.
</td></tr>

<tr><td>LadyBug-5
</td><td>8000
</td><td>1.5 mm
</td><td>4 mm
</td><td>16 mm
</td><td>10 fps at this resolution.<br>Spherical.
</td></tr>

<tr><td>H3Pro7HD (Kolor)
</td><td>8000
</td><td>1.5 mm
</td><td>4 mm
</td><td>16 mm
</td><td>7 GoPro cameras mounted in portrait.<br>Cylindrical.
</td></tr>

<tr><td>H3Pro7 (Kolor)
</td><td>6000
</td><td>2 mm
</td><td>5 mm
</td><td>21 mm
</td><td>7 GoPro cameras.<br>Spherical.
</td></tr>

<tr><td>Lucy (Kogeto)
</td><td>2000
</td><td>6 mm
</td><td>16 mm
</td><td>63 mm
</td><td><a href="../../panorama/LucyCamera/index.html">Example of camera based upon 1920 video</a>.<br>Cylindrical.
</td></tr>

<tr><td>Joey (Kogeto)
</td><td>4000
</td><td>3 mm
</td><td>8 mm
</td><td>31 mm
</td><td>Not yet available at time of writing.<br>Cylindrical.
</td></tr>

<tr><td>Bublcam
</td><td>2500
</td><td>5 mm
</td><td>13mm
</td><td>50
</td><td>Not yet available at time of writing.<br>4 x 720p camera at 30fps.<br>Spherical.
</td></tr>

<tr><td>Bublcam
</td><td>3600
</td><td>3.5 mm
</td><td>8 mm
</td><td>35 mm
</td><td>Not yet available at time of writing.<br>4 x 1920p camera at 15fps.<br>Spherical.
</td></tr>

<tr><td>Centrcam
</td><td>6900
</td><td>1.8 mm
</td><td>4.5 mm
</td><td>18 mm
</td><td>Not yet available at time of writing.<br>Maximum 30fps.<br>Cylindrical.
</td></tr>

<!--
<tr><td>
</td><td>
</td><td>
</td><td>
</td><td>
</td><td>
</td></tr>
-->

</table></center><p>

<b>Confounding factors</b><p>

<p align="justify">
In the above it has been assumed that if a device can capture N pixels horizontally, then
those pixels are "pure", this is never the case. Further degradation can occur and some sources
are listed below.
</p>
<ul>
<li><p align="justify">
Many of the camera solution do not result in a uniform resolution across the cylindrical or
spherical projection. This is particularly true of single camera solutions based upon
conical mirrors.
<p>

<li><p align="justify">
In the case of many commodity devices, while they may contain the same sensor as more
expensive versions, there can be a poorer quality lens in front of the sensor. This generally
means that pixels are no longer independent (they receive light over a wider region of the
world) and generally an increase in chromatic error.
This is particularly true of many of the mobile phone based options.
</p>

<li><p align="justify">
Different sensors have different levels of random noise, especially in low light.
</p>

<li><p align="justify">
Digital video capture is often limited by the bandwidth to the recording device. To maintain
a recording resolution and frame rate the video is generally compressed with corresponding
artefacts. The slower the recording device, the more compression and video degradation that
occurs. Particularly so with SD storage medium in the GoPro, and others.
</p>

<li><p align="justify">
While the only scalable means of increasing the resolution is to use multiple cameras, this
introduces potential resolution degradation across the overlap and blending zone. While there
are multiple camera configurations, that with the use of mirrors, can create a single projection
point, the majority have an offset projection point. For very fundamental reasons this means
that a perfect stitch/blend across all depths is impossible.
<p>
</ul>
<p>

<br>

<center>
<h1>Resolution of display technologies</h1>
Written by <a href="../index.html">Paul Bourke</a><br>
January 2007
</center>

<b>Introduction</b><br>
<p align="justify">
The resolution of a digital display is a key component of the perceived quality. There
are a number of factors that affect the resolution, such as: projector lens quality, 
interpixel leakage, surface properties, compression codes, geometry distortion, keystone,
colour space, 
and so on. However one can calculate the upper quality possible by the display system
by assuming a perfect system where the above have no degrading effect 
and considering just the pixel resolution.
The figure of merit proposed is the angle a pixel subtends at the eye, convenient units
for the scale of most current displays is arc seconds. This definition of resolution for
some common devices is shown in the chart below, there is a bias/interest in displays the
author has been involved in.
</p>

<b>Comparison chart</b><p>
<table width=100% cellspacing=0 cellpadding=5 border=1>
<tr>
<td bgcolor="#dddddd"><b>Display type</b></td>
<td bgcolor="#dddddd"><b>Projection resolution</b></td>
<td bgcolor="#dddddd"><b>Dimensions</b></td>
<td bgcolor="#dddddd"><b>Viewing distance</b></td>
<td bgcolor="#dddddd"><b>Resolution<br>(arc seconds)</b></td>
</tr>

<tr>
<td><b>Apple 30" display</b></td>
<td>2560x1600</td>
<td>30 inch diagonal</td>
<td>600mm</td>
<td>86</td>
</tr>

<tr>
<td><b>Standard 17" display</b></td>
<td>1280x1024</td>
<td>17 inch diagonal</td>
<td>600mm</td>
<td>92</td>
</tr>

<tr>
<td><b>iPod video</b></td>
<td>320x240</td>
<td>2.5 inch diagonal</td>
<td>300mm</td>
<td>109</td>
</tr>

<tr>
<td><b>Flat screen projection (VROOM)</b></td>
<td>XGA (1024x768) projector</td>
<td>2m wide</td>
<td>2m</td>
<td>201</td>
</tr>

<tr>
<td><b>Flat screen projection</b></td>
<td>SXGA+ (1400x1050) projector</td>
<td>2m wide</td>
<td>2m</td>
<td>149</td>
</tr>

<tr>
<td><b>Flat screen projection</b></td>
<td>HD (1920x1080) projector</td>
<td>2m wide</td>
<td>2m</td>
<td>109</td>
</tr>

<tr>
<td><b>Dome</b></td>
<td>Full fisheye, XGA (1024x768) projector</td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>539</td>
</tr>

<tr>
<td><b>Dome</b></td>
<td>Full fisheye, SXGA+ (1400x1050) projector</td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>395</td>
</tr>

<tr>
<td><b>Dome</b></td>
<td>Truncated fisheye, SXGA+ (1400x1050) projector<br>
75% coverage</td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>292</td>
</tr>

<tr>
<td><b>Dome</b></td>
<td>Truncated fisheye, HD (1920x1080) projector<br>
56% coverage</td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>218</td>
</tr>

<tr>
<td><b>Dome</b></td>
<td>Spherical mirror<sup>**</sup> and HD (1920x1080) projector<br>
Full dome coverage and 2/3 of the pixels used</td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>309</td>
</tr>

<tr>
<td><b>Dome</b></td>
<td>Spherical mirror<sup>**</sup> and HD (1920x1080) projector<br>
80% dome coverage and 3/4 of the pixels used</td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>264</td>
</tr>

<tr>
<td><b>Dome (planetarium)</b></td>
<td>6 projectors, each SXGA+ (1400x1050)<br>
<smalltext>Assume each projector contributes 2/3 of its pixels to the final image</smalltext></td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>149</td>
</tr>

<tr>
<td><b>Dome (planetarium)</b></td>
<td>6 projectors, each HD (1920x1080)<br>
<smalltext>Assume each projector contributes 2/3 of its pixels to the final image</smalltext></td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>126</td>
</tr>

<tr>
<td><b>Dome (planetarium)</b></td>
<td>Full dome using two SONY 4kx2k projectors<br>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>103</td>
</tr>

<tr>
<td><b><a href="../../panorama/cylinder/index.html">Cylinder (AVIE)</a></b></td>
<td>6 projectors, each SXGA+ (1400x1050)<br>
<smalltext>Assume 200 pixel edgeblend</smalltext></td>
<td><sup>*</sup></td>
<td>Located at center</td>
<td>178</td>
</tr>

<tr>
<td><b>Neptune</b></td>
<td></td>
<td></td>
<td>From Earth</td>
<td>2.5</td>
</tr>

<tr>
<td><b>Mars</b></td>
<td></td>
<td></td>
<td>From Earth</td>
<td>20</td>
</tr>

<!--
<tr>
<td><b></b></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
-->

</table><p>

<b>Notes</b><p>
<ul>
<li><sup>*</sup>For the dome and cylindrical environments the resolution is independent of the
size of the display assuming the observer is at the central sweet spot. As the dimensions of the
surface get larger the observer gets further away.
<p>

<li>For the multiple projector domes it is assumed that 2/3 of the display area of
each projector contributes to the final image. This does depend on the aspect ratio of
the projectors being used but is the upper limit for standard geometry corrected and
edge blended frames.
<p>

<li><sup>**</sup>The spherical mirror projection does not result in equal size pixels
across the dome and it is possible to vary the dome coverage from the same as a truncated
fisheye to 100%. Some parts of the dome will be higher resolution, others lower.<p>
</ul>

<b>Equations</b><p>
In what follows the following symbols are used.<br>
x y are the physical linear dimensions, width and height<br>
r is the radius<br>
w h are the pixel dimensions, width and height<br>
d is the viewing distance<br>
n is the number of projectors
<p>
A small angle approximation is used, namely tan(x) = x for small values of x.
<p>

<b>Planar display, single projector</b><br>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>x y</center></td>
<td></td>
</tr>
<tr>
<td>resolution = sqrt[</td>
<td>-------</td>
<td>] / d</td>
</tr>
<tr>
<td></td>
<td><center>w h</center></td>
<td></td>
</tr>
</table>
</center><p>
If the pixels are square and all are used then this reduces to<p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>x</center></td>
</tr>
<tr>
<td>resolution = </td>
<td>-------</td>
</tr>
<tr>
<td></td>
<td><center>w d</center></td>
</tr>
</table>
</center><p>

<b>Cylindrical display</b><br>
Take the edge blend width in pixels into account for "w", the pixel width of each projector.
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>2 pi r</center></td>
<td></td>
</tr>
<tr>
<td>resolution = [</td>
<td>-------</td> 
<td>] / d</td>
</tr> 
<tr>
<td></td>
<td><center>n w</center></td>
<td></td>
</tr>
</table>
</center><p>
If the viewer is standing in the center this reduces to<p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>2 pi</center></td>
<td></td>
</tr>
<tr>
<td>resolution = </td>
<td>-------</td>
<td></td>
</tr>
<tr>
<td></td>
<td><center>n w</center></td>
<td></td>
</tr>
</table>
</center><p>

<b>Multiprojector Dome eg: planetarium</b><br>
Assume each projector contributes 2/3 of its pixels to the final image.<p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>pi r<sup>2</sup></center></td>
<td></td>
</tr>
<tr>
<td>resolution = sqrt[</td>
<td>----------------</td> 
<td>] / d</td>
</tr> 
<tr>
<td></td>
<td><center>n (2/3) w h</center></td>
<td></td>
</tr>
</table>
</center><p>
If the viewer is located in the center then this reduces to<p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>pi</center></td>
<td></td>
</tr>
<tr>
<td>resolution = sqrt[</td>
<td>----------------</td>
<td>]</td>
</tr>
<tr>
<td></td>
<td><center>n (2/3) w h</center></td>
<td></td>
</tr>
</table>
</center><p>

<b>Dome projection with a single full fisheye</b><p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>pi r<sup>2</sup></center></td>
<td></td>
</tr>
<tr>
<td>resolution = sqrt[</td>
<td>----------</td>
<td>] / d</td>
</tr>
<tr>
<td></td>
<td><center>pi h / 2</center></td>
<td></td>
</tr>
</table>
</center><p>
For the observer at the center of the dome this reduces to<p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>1</center></td>
<td></td>
</tr>
<tr>
<td>resolution = </td>
<td>----------</td>
<td></td>
</tr>
<tr>
<td></td>
<td><center>h / 2</center></td>
<td></td>
</tr>
</table>
</center><p>

<b>Dome projection with a 3/4 truncated fisheye</b><p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>pi r<sup>2</sup></center></td>
<td></td>
</tr>
<tr>
<td>resolution = sqrt[</td>
<td>----------</td>
<td>] / d</td>
</tr>
<tr>
<td></td>
<td><center>pi w / 2</center></td>
<td></td>
</tr>
</table>
</center><p>
For the observer at the center of the dome this reduces to<p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>1</center></td>
<td></td>
</tr>
<tr>
<td>resolution = </td>
<td>----------</td>
<td></td>
</tr>
<tr>
<td></td>
<td><center>w / 2</center></td>
<td></td>
</tr>
</table>
</center><p>

<b>Dome projection using a single projector and spherical mirror</b><p>
Assume p% of the pixels end up on the dome that is q% covered.
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>q pi r<sup>2</sup></center></td>
<td></td>
</tr>
<tr>
<td>resolution = sqrt[</td>
<td>-----------</td> 
<td>] / d</td>
</tr> 
<tr>
<td></td>
<td><center>p w h</center></td>
<td></td>
</tr>
</table>
</center><p>
For the observer at the center of the dome this reduces to<p>
<center>
<table cellpadding=0 cellspacing=0>
<tr>
<td></td>
<td><center>q pi</center></td>
<td></td>
</tr>
<tr>
<td>resolution = </td>
<td>-----------</td>
<td></td>
</tr>
<tr>
<td></td>
<td><center>p w h</center></td>
<td></td>
</tr>
</table>
</center><p>

</body>
</html>
