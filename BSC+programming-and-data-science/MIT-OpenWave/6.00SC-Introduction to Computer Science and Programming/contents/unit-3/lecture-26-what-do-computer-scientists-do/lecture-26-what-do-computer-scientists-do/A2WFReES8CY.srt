1
00:00:00,570 --> 00:00:02,990
The following content is
provided under a Creative

2
00:00:02,990 --> 00:00:04,410
Commons license.

3
00:00:04,410 --> 00:00:07,440
Your support will help MIT
OpenCourseWare continue to

4
00:00:07,440 --> 00:00:11,100
offer high quality educational
resources for free.

5
00:00:11,100 --> 00:00:13,990
To make a donation or view
additional materials from

6
00:00:13,990 --> 00:00:17,920
hundreds of MIT courses, visit
MIT OpenCourseWare at

7
00:00:17,920 --> 00:00:19,170
ocw.mit.edu.

8
00:00:30,060 --> 00:00:33,290
PROFESSOR: Now today's
lecture.

9
00:00:33,290 --> 00:00:35,570
First I want to talk a little
bit about what computer

10
00:00:35,570 --> 00:00:36,720
scientists do.

11
00:00:36,720 --> 00:00:39,960
This whole course has been
about computer science.

12
00:00:39,960 --> 00:00:42,980
And I hope that at least for
many of you, it might have

13
00:00:42,980 --> 00:00:45,610
persuaded you that there's an
interesting career out there

14
00:00:45,610 --> 00:00:48,090
for you as a computer
scientist.

15
00:00:48,090 --> 00:00:51,370
And then I'll finish up with an
overview of what I think we

16
00:00:51,370 --> 00:00:53,280
covered this term.

17
00:00:53,280 --> 00:00:55,260
So what do computer
scientists do?

18
00:00:55,260 --> 00:00:58,170
Well, they look a lot like
that as you all know.

19
00:01:00,820 --> 00:01:02,680
In fact, it's amazing.

20
00:01:02,680 --> 00:01:06,360
There's almost nothing that
computer scientists don't do.

21
00:01:06,360 --> 00:01:10,350
So here I've just collected a
few of the different pictures

22
00:01:10,350 --> 00:01:14,820
related to what computer
scientists in EECS are doing

23
00:01:14,820 --> 00:01:18,760
these days, things like working
on the software that

24
00:01:18,760 --> 00:01:21,990
keeps airplanes from falling
out of the skies.

25
00:01:21,990 --> 00:01:25,020
Quite a few people working in
the movie industry these days

26
00:01:25,020 --> 00:01:30,180
doing animations in 3D and
that sort of thing.

27
00:01:30,180 --> 00:01:32,610
These days, computer scientists
don't get paid as

28
00:01:32,610 --> 00:01:34,250
much as the actors.

29
00:01:34,250 --> 00:01:37,990
But they get paid a lot
to produce movies.

30
00:01:37,990 --> 00:01:41,150
Robots, of course.

31
00:01:41,150 --> 00:01:44,680
A lot of medical work,
particularly medical imaging.

32
00:01:44,680 --> 00:01:47,930
This is a picture where someone
has written software

33
00:01:47,930 --> 00:01:52,520
to try and identify the tumors
in the human brain, and then

34
00:01:52,520 --> 00:01:56,450
will draw little lines telling
the surgeon where to cut so as

35
00:01:56,450 --> 00:01:59,450
to do the least damage
and the most good.

36
00:01:59,450 --> 00:02:01,090
A lot of work in genetics.

37
00:02:01,090 --> 00:02:03,640
And of course, core things
like making the internet

38
00:02:03,640 --> 00:02:08,270
actually not crash.

39
00:02:08,270 --> 00:02:13,040
Fundamentally, what computer
scientists do is they think

40
00:02:13,040 --> 00:02:14,980
computationally.

41
00:02:14,980 --> 00:02:18,240
And I hope that you've
understood that that's been

42
00:02:18,240 --> 00:02:23,260
the theme of 6.00, is how to
formulate problems and think

43
00:02:23,260 --> 00:02:25,300
computationally.

44
00:02:25,300 --> 00:02:30,650
This will be, I think, the most
important skill used by

45
00:02:30,650 --> 00:02:33,740
certainly scientists and
engineers but, in fact,

46
00:02:33,740 --> 00:02:38,330
everybody by the middle of the
21st century or sooner.

47
00:02:38,330 --> 00:02:42,090
People will just do everything
computationally.

48
00:02:42,090 --> 00:02:46,000
And just as once upon a time
maybe it's still important

49
00:02:46,000 --> 00:02:48,100
everyone learn to read and
write and do a little

50
00:02:48,100 --> 00:02:53,740
arithmetic, people will think
that computation is exactly as

51
00:02:53,740 --> 00:02:58,570
important and that you'll have
to know how to formulate

52
00:02:58,570 --> 00:03:04,010
problems computationally
to survive in society.

53
00:03:04,010 --> 00:03:08,470
The process, and this is what
we've been doing all term, is

54
00:03:08,470 --> 00:03:10,150
not an easy one.

55
00:03:10,150 --> 00:03:13,840
But it's not an impossible
one either.

56
00:03:13,840 --> 00:03:19,050
We begin by identifying and
inventing useful abstractions.

57
00:03:19,050 --> 00:03:22,430
Everything we do is an
abstraction of reality.

58
00:03:22,430 --> 00:03:26,250
And as we've gone through the
second half of the term,

59
00:03:26,250 --> 00:03:30,300
almost every interesting
computation we've designed

60
00:03:30,300 --> 00:03:33,470
starts with inventing classes
that give us useful data

61
00:03:33,470 --> 00:03:39,200
abstraction or functions that
compute useful things.

62
00:03:39,200 --> 00:03:41,170
And that's sort of what
we start with.

63
00:03:41,170 --> 00:03:45,130
We start with some existing set
of abstractions, and we

64
00:03:45,130 --> 00:03:48,260
invent new ones that
will help us think

65
00:03:48,260 --> 00:03:51,100
about the current problem.

66
00:03:51,100 --> 00:03:53,760
We then formulate the solution
to the problem as a

67
00:03:53,760 --> 00:03:59,690
computational experiment and
then design and construct a

68
00:03:59,690 --> 00:04:02,540
sufficiently efficient
implementation.

69
00:04:02,540 --> 00:04:06,100
It doesn't have to be the most
efficient one possible.

70
00:04:06,100 --> 00:04:09,580
It just has to be efficient
enough that we can run it and

71
00:04:09,580 --> 00:04:11,460
get an answer.

72
00:04:11,460 --> 00:04:14,930
Of course, before we trust
the answer, as with any

73
00:04:14,930 --> 00:04:17,200
experimental apparatus--

74
00:04:17,200 --> 00:04:20,500
and it is an experimental
apparatus, a program--

75
00:04:20,500 --> 00:04:24,450
we need to validate the
experiment, convince ourselves

76
00:04:24,450 --> 00:04:27,640
that when we run it, we should
believe the answer.

77
00:04:27,640 --> 00:04:30,310
That's the process
of debugging.

78
00:04:30,310 --> 00:04:32,950
And I'm sure it's a process
that all of you have spent

79
00:04:32,950 --> 00:04:36,060
more time on this term then
you might have liked.

80
00:04:36,060 --> 00:04:38,806
I hope by now you feel you are a
little bit better at it than

81
00:04:38,806 --> 00:04:41,060
you used to be.

82
00:04:41,060 --> 00:04:43,500
Once we think we've got the
experiment put together

83
00:04:43,500 --> 00:04:45,620
properly, we run it.

84
00:04:45,620 --> 00:04:47,680
We then evaluate the results.

85
00:04:47,680 --> 00:04:51,310
And then we repeat as
needed, the classic

86
00:04:51,310 --> 00:04:54,516
iterative style of science.

87
00:04:54,516 --> 00:04:58,330
And a lot of this, of course, is
what you would have learned

88
00:04:58,330 --> 00:05:02,200
in your chemistry lab or your
physics lab or the bio lab in

89
00:05:02,200 --> 00:05:04,290
designing any experiment.

90
00:05:04,290 --> 00:05:07,260
You have to go through
a lot of these steps.

91
00:05:07,260 --> 00:05:10,240
And the difference is these
are all computational

92
00:05:10,240 --> 00:05:12,250
experiments.

93
00:05:12,250 --> 00:05:14,250
So we think of there
are two ways of

94
00:05:14,250 --> 00:05:16,260
computational thinking.

95
00:05:16,260 --> 00:05:17,820
There's abstraction.

96
00:05:17,820 --> 00:05:19,490
You have to choose the
right abstraction.

97
00:05:22,490 --> 00:05:26,940
Typically, we operate in terms
of multiple layers of

98
00:05:26,940 --> 00:05:29,520
abstraction simultaneously.

99
00:05:29,520 --> 00:05:33,670
And this is an important part
of thinking computationally.

100
00:05:33,670 --> 00:05:38,920
We have to be able to not worry
about, say, the details

101
00:05:38,920 --> 00:05:41,970
of how floating point numbers
were implemented, but just

102
00:05:41,970 --> 00:05:42,910
assume it's a good

103
00:05:42,910 --> 00:05:45,850
approximation of the real numbers.

104
00:05:45,850 --> 00:05:48,230
That's one level
of abstraction.

105
00:05:48,230 --> 00:05:51,410
And another level of
abstraction, we think about

106
00:05:51,410 --> 00:05:53,570
bus stop queues.

107
00:05:53,570 --> 00:05:55,755
And maybe we have to implement
those ourselves.

108
00:05:59,040 --> 00:06:02,020
And then we have to think about
the relationships among

109
00:06:02,020 --> 00:06:03,810
the layers.

110
00:06:03,810 --> 00:06:06,930
A key thing that makes
computational abstractions

111
00:06:06,930 --> 00:06:12,610
different from so many others
is we can automate them.

112
00:06:12,610 --> 00:06:16,270
So we often think about
abstractions as we go through

113
00:06:16,270 --> 00:06:19,900
life and think about how to cope
with things that are too

114
00:06:19,900 --> 00:06:22,120
complex to understand.

115
00:06:22,120 --> 00:06:24,020
We have these various
abstractions.

116
00:06:24,020 --> 00:06:27,110
Newton gave us some good
abstractions of the physical

117
00:06:27,110 --> 00:06:30,630
world that let us understand
how things like levers and

118
00:06:30,630 --> 00:06:32,880
such almost how they work.

119
00:06:35,450 --> 00:06:39,150
But here we get the big
advantage that we not only can

120
00:06:39,150 --> 00:06:42,510
invent an abstraction,
we can mechanize it.

121
00:06:42,510 --> 00:06:44,570
We can do this for
two reasons.

122
00:06:44,570 --> 00:06:50,510
One, we have a precise and
exacting notation for

123
00:06:50,510 --> 00:06:53,010
expressing the abstractions
for building our

124
00:06:53,010 --> 00:06:55,510
computational models.

125
00:06:55,510 --> 00:07:00,250
This term, that has been Python
and PyLab and NumPy.

126
00:07:00,250 --> 00:07:01,840
But it could have been Java.

127
00:07:01,840 --> 00:07:03,370
It could have been C++.

128
00:07:03,370 --> 00:07:05,260
It could have been MATLAB.

129
00:07:05,260 --> 00:07:07,290
Doesn't matter very much.

130
00:07:07,290 --> 00:07:11,350
What matters is that we have a
notation that's precise enough

131
00:07:11,350 --> 00:07:14,270
that we can actually describe
a computation.

132
00:07:14,270 --> 00:07:21,100
And we have some machine that
can take a computation written

133
00:07:21,100 --> 00:07:24,780
in that notation, or a set of
computations actually written

134
00:07:24,780 --> 00:07:30,320
in that notation, and execute
them and give us results.

135
00:07:30,320 --> 00:07:33,330
And that's been the big
transformation that has made

136
00:07:33,330 --> 00:07:35,910
computation so important.

137
00:07:35,910 --> 00:07:38,850
We've had the notion of
computation long before we had

138
00:07:38,850 --> 00:07:40,920
machines that could
execute them.

139
00:07:40,920 --> 00:07:43,760
The Greeks, the Egyptians
understood notions of

140
00:07:43,760 --> 00:07:48,330
computation, as we've seen
before when we looked at some

141
00:07:48,330 --> 00:07:49,530
early algorithms.

142
00:07:49,530 --> 00:07:51,920
Algorithms have been
around a long time.

143
00:07:51,920 --> 00:07:55,780
But nobody cared very much
until we had machines and

144
00:07:55,780 --> 00:08:00,490
notations that would let us
actually run the algorithms.

145
00:08:00,490 --> 00:08:02,610
That came along in
the late '40s.

146
00:08:02,610 --> 00:08:05,125
And then the world changed
dramatically.

147
00:08:07,640 --> 00:08:11,490
So some examples of
computational thinking.

148
00:08:11,490 --> 00:08:17,220
How difficult is this problem,
and how best can I solve it?

149
00:08:17,220 --> 00:08:20,390
And that's what theoretical
computer scientists spend

150
00:08:20,390 --> 00:08:22,640
their time thinking about.

151
00:08:22,640 --> 00:08:25,590
They try to give precise
meanings to these kinds of

152
00:08:25,590 --> 00:08:31,310
questions so that we can ask
them in the context of, say,

153
00:08:31,310 --> 00:08:35,200
random access machines or
parallel machines or, more

154
00:08:35,200 --> 00:08:40,120
lately, quantum machines, how
do we formulate those

155
00:08:40,120 --> 00:08:41,440
questions precisely?

156
00:08:41,440 --> 00:08:45,280
And how can we answer them?

157
00:08:45,280 --> 00:08:49,180
And of course, thinking
recursively is very important.

158
00:08:49,180 --> 00:08:54,640
Fundamentally, it's the key in
that what we try and do is we

159
00:08:54,640 --> 00:08:58,840
try and reformulate a seemingly
difficult problem

160
00:08:58,840 --> 00:09:01,720
into one we already
know how to solve.

161
00:09:01,720 --> 00:09:04,100
This is what we talked about
before, reduction to a

162
00:09:04,100 --> 00:09:06,800
previously solved problem.

163
00:09:06,800 --> 00:09:09,040
And we've looked at different
ways of doing this.

164
00:09:09,040 --> 00:09:11,870
There is reduction,
as I mentioned.

165
00:09:11,870 --> 00:09:16,380
There's embedding, where, OK,
our problem is complex.

166
00:09:16,380 --> 00:09:19,320
We can't reduce it to
a different problem.

167
00:09:19,320 --> 00:09:22,350
But we can embed a different
problem in it as at least part

168
00:09:22,350 --> 00:09:24,020
of the solution.

169
00:09:24,020 --> 00:09:27,380
We can do some transformations,
take one

170
00:09:27,380 --> 00:09:31,840
problem and transform it
to a different problem.

171
00:09:31,840 --> 00:09:35,250
Usually, a simpler problem that
we know how to solve.

172
00:09:35,250 --> 00:09:37,130
We've seen a lot of that.

173
00:09:37,130 --> 00:09:39,620
That's, of course, what you've
seen in the bus simulation

174
00:09:39,620 --> 00:09:42,610
you're studying, I hope as--

175
00:09:42,610 --> 00:09:45,820
I hope not as I speak, but as
soon as I finish speaking,

176
00:09:45,820 --> 00:09:48,240
you'll be studying it.

177
00:09:48,240 --> 00:09:52,600
We've taken a complex problem
and simplified it by

178
00:09:52,600 --> 00:09:54,730
transforming it into
a simpler problem

179
00:09:54,730 --> 00:09:56,910
that we can then attack.

180
00:09:56,910 --> 00:10:02,570
And we've used a lot of
simulation as a mechanism for

181
00:10:02,570 --> 00:10:03,640
dealing with problems.

182
00:10:03,640 --> 00:10:05,850
So here's a little recursive
picture.

183
00:10:05,850 --> 00:10:09,880
Here's one of my favorite
illustrations of recursion.

184
00:10:09,880 --> 00:10:11,490
I don't know how they
did that, but I

185
00:10:11,490 --> 00:10:13,920
think it's pretty cool.

186
00:10:13,920 --> 00:10:14,350
All right.

187
00:10:14,350 --> 00:10:18,250
That's a very quick
introduction, at a very

188
00:10:18,250 --> 00:10:22,600
abstract level, what computer
scientists might do.

189
00:10:22,600 --> 00:10:25,460
I'm gonna spend some time now
on what one particular

190
00:10:25,460 --> 00:10:28,570
computer scientist does,
and that's me.

191
00:10:28,570 --> 00:10:30,490
Why did I choose me?

192
00:10:30,490 --> 00:10:32,530
Well, not because I'm the most
interesting, but because I'm

193
00:10:32,530 --> 00:10:34,400
the one I know the best.

194
00:10:34,400 --> 00:10:37,020
So it's kind of easier for me
to talk about my work than

195
00:10:37,020 --> 00:10:38,880
about somebody else's.

196
00:10:38,880 --> 00:10:43,740
And the truth be told, it's
not actually my work.

197
00:10:43,740 --> 00:10:47,780
Like all professors, I claim
credit for the work that my

198
00:10:47,780 --> 00:10:49,390
students do.

199
00:10:49,390 --> 00:10:51,970
So all of the work you're going
to see is actually work

200
00:10:51,970 --> 00:10:53,600
that my students have done.

201
00:10:53,600 --> 00:10:55,680
Mostly graduate students,
but also some

202
00:10:55,680 --> 00:10:57,920
very productive UROPs.

203
00:10:57,920 --> 00:11:01,740
So, I won't give them as much
credit as I should, but you

204
00:11:01,740 --> 00:11:04,390
should know in your heart that
I didn't do any of this

205
00:11:04,390 --> 00:11:06,090
actually myself.

206
00:11:06,090 --> 00:11:06,360
All right.

207
00:11:06,360 --> 00:11:08,650
What do we do?

208
00:11:08,650 --> 00:11:12,260
The goals of our research group
is the rather modest one

209
00:11:12,260 --> 00:11:16,010
of helping people live longer
and better quality lives.

210
00:11:16,010 --> 00:11:19,590
Other than that, we don't intend
to accomplish anything.

211
00:11:19,590 --> 00:11:22,770
And we do this mostly in the
medical area by collaborating

212
00:11:22,770 --> 00:11:27,180
with clinical researchers and
practicing clinicians.

213
00:11:27,180 --> 00:11:31,490
Along the way we have a lot of
fun pushing the frontiers, the

214
00:11:31,490 --> 00:11:33,990
state of the art in computer
science, electrical

215
00:11:33,990 --> 00:11:38,140
engineering, and certainly
medicine.

216
00:11:38,140 --> 00:11:41,570
We use a lot of the technical
kind of ideas you've seen this

217
00:11:41,570 --> 00:11:45,200
semester and that you'll see in
almost any computer science

218
00:11:45,200 --> 00:11:46,820
course you take.

219
00:11:46,820 --> 00:11:49,760
We do a lot of machine learning
and data mining.

220
00:11:49,760 --> 00:11:52,100
I'll explain why shortly.

221
00:11:52,100 --> 00:11:54,920
We do a lot of algorithm design
because a lot of the

222
00:11:54,920 --> 00:11:59,090
problems we're trying to solve
are too complex to solve if

223
00:11:59,090 --> 00:12:02,000
you're not clever about
how you solve them.

224
00:12:02,000 --> 00:12:04,250
We do some signal processing.

225
00:12:04,250 --> 00:12:06,430
I'll explain why we do that.

226
00:12:06,430 --> 00:12:10,290
And a lot of just plain-old
software systems are needed.

227
00:12:10,290 --> 00:12:12,405
Do we use databases?

228
00:12:12,405 --> 00:12:16,350
How we build software that
injects electrical signals

229
00:12:16,350 --> 00:12:17,940
into people's brains?

230
00:12:17,940 --> 00:12:20,110
So we spend a fair amount of
time trying to convince

231
00:12:20,110 --> 00:12:24,110
ourselves it actually works,
doesn't inject the wrong

232
00:12:24,110 --> 00:12:25,740
signals at the wrong time.

233
00:12:25,740 --> 00:12:28,880
But that might be fun too.

234
00:12:28,880 --> 00:12:30,800
And these are just the
logos of some of the

235
00:12:30,800 --> 00:12:32,390
hospitals we work with.

236
00:12:32,390 --> 00:12:36,310
So what are some of the problems
we try and deal with?

237
00:12:36,310 --> 00:12:39,790
Probably our longest standing
project has to do with medical

238
00:12:39,790 --> 00:12:41,310
telepresence.

239
00:12:41,310 --> 00:12:45,270
These hands do not belong
to a basketball player.

240
00:12:45,270 --> 00:12:48,580
These are normal sized hands
like yours or mine.

241
00:12:48,580 --> 00:12:51,330
That is not a normal
sized baby.

242
00:12:51,330 --> 00:12:52,880
This is not a Photoshop photo.

243
00:12:52,880 --> 00:12:54,550
This is a real photo.

244
00:12:54,550 --> 00:12:58,310
This is a very small
premature baby.

245
00:12:58,310 --> 00:13:01,280
And we have spent a lot of
time working with groups

246
00:13:01,280 --> 00:13:05,180
figuring out how to provide
better outcomes for these tiny

247
00:13:05,180 --> 00:13:09,530
little, very delicate people.

248
00:13:09,530 --> 00:13:13,840
A problem is that a lot of
these babies are born--

249
00:13:13,840 --> 00:13:17,870
if these babies are born in the
right hospital, Brigham

250
00:13:17,870 --> 00:13:20,510
and Women's Hospital or
something close to Children's

251
00:13:20,510 --> 00:13:24,610
Hospital or MGH, they have
very good outcomes.

252
00:13:24,610 --> 00:13:28,770
They tend to survive, and they
tend to grow up to be

253
00:13:28,770 --> 00:13:30,540
relatively normal.

254
00:13:30,540 --> 00:13:34,740
If these babies are born in a
community hospital that does

255
00:13:34,740 --> 00:13:38,240
not know how to take care of
these kinds of babies, they

256
00:13:38,240 --> 00:13:40,420
have very bad outcomes.

257
00:13:40,420 --> 00:13:42,060
A lot of them die.

258
00:13:42,060 --> 00:13:46,840
Many of them who survive end up
being permanently disabled.

259
00:13:46,840 --> 00:13:48,090
Very sad.

260
00:13:53,180 --> 00:13:58,360
One of the shocking statistics
is that globally there's a

261
00:13:58,360 --> 00:14:01,900
neonatal death every
10 seconds.

262
00:14:01,900 --> 00:14:03,770
Shocking number, I think.

263
00:14:03,770 --> 00:14:05,740
It's just tragic.

264
00:14:05,740 --> 00:14:07,830
And many of these
are unnecessary.

265
00:14:07,830 --> 00:14:10,680
And they occur because there's
not adequate care at the point

266
00:14:10,680 --> 00:14:12,330
where the baby is born.

267
00:14:12,330 --> 00:14:16,380
And so we've been trying to use
technology to link places

268
00:14:16,380 --> 00:14:19,590
where these babies might be born
to places where people

269
00:14:19,590 --> 00:14:22,770
can advise how to take
care of them.

270
00:14:22,770 --> 00:14:25,820
And it turns out to be a very
interesting set of computer

271
00:14:25,820 --> 00:14:28,150
networking communications
problems.

272
00:14:28,150 --> 00:14:31,300
You can't just use Skype
for reasons I won't

273
00:14:31,300 --> 00:14:32,850
have time to go into.

274
00:14:32,850 --> 00:14:34,400
But it's very exciting.

275
00:14:34,400 --> 00:14:37,490
It uses a lot of computer
science, a lot of medicine,

276
00:14:37,490 --> 00:14:40,210
but mostly computer science,
in this case.

277
00:14:40,210 --> 00:14:43,810
And we're actually currently
running some trials in

278
00:14:43,810 --> 00:14:47,050
conjunction with Children's
Hospital Boston where they're

279
00:14:47,050 --> 00:14:49,970
actually trying to look at
babies born elsewhere.

280
00:14:53,510 --> 00:14:55,680
Another problem we've been
looking at is health-care

281
00:14:55,680 --> 00:14:57,820
associated infections.

282
00:14:57,820 --> 00:15:03,210
Approximately 1 in 20 hospital
visits results in the patient

283
00:15:03,210 --> 00:15:06,540
contracting an infection totally
unrelated to the

284
00:15:06,540 --> 00:15:09,990
reason they entered
the hospital.

285
00:15:09,990 --> 00:15:13,430
And today it's among the top ten
leading causes of death in

286
00:15:13,430 --> 00:15:15,670
the United States.

287
00:15:15,670 --> 00:15:19,500
Somebody enters a hospital for
a reason x, picks up an

288
00:15:19,500 --> 00:15:23,110
infection unrelated
to x, and dies.

289
00:15:23,110 --> 00:15:24,400
Not a very good outcome.

290
00:15:26,980 --> 00:15:28,950
And it's particularly
discouraging because, in

291
00:15:28,950 --> 00:15:32,600
principle, these infections
should be preventable.

292
00:15:32,600 --> 00:15:35,560
You shouldn't acquire a
life-threatening infection

293
00:15:35,560 --> 00:15:38,630
while you're in the hospital.

294
00:15:38,630 --> 00:15:39,890
But people do.

295
00:15:39,890 --> 00:15:42,580
We've been trying to
understand why.

296
00:15:42,580 --> 00:15:46,320
We've been working on this
project with Microsoft, which

297
00:15:46,320 --> 00:15:51,030
has provided us with data from
4.5 million different hospital

298
00:15:51,030 --> 00:15:57,990
visits and about 2000 pieces of
information per visit, lab

299
00:15:57,990 --> 00:16:01,670
tests, drug tests, who the
doctors were, who the nurses

300
00:16:01,670 --> 00:16:05,580
were, what rooms they were in.

301
00:16:05,580 --> 00:16:08,100
And we're trying to study--
these are pictures of some of

302
00:16:08,100 --> 00:16:12,200
the most obnoxious of
these infections--

303
00:16:12,200 --> 00:16:17,110
and we've been trying to figure
out what's causing them

304
00:16:17,110 --> 00:16:20,220
and what can be done
not to cause them.

305
00:16:20,220 --> 00:16:25,600
This has been primarily a
machine learning project.

306
00:16:25,600 --> 00:16:28,660
We've been struggling with it.

307
00:16:28,660 --> 00:16:31,360
We've been dealing with exactly
some of the issues we

308
00:16:31,360 --> 00:16:33,080
talked about in class.

309
00:16:33,080 --> 00:16:34,820
Which features are
most important?

310
00:16:34,820 --> 00:16:38,390
How should you weight the
different features?

311
00:16:38,390 --> 00:16:41,040
How can we reduce the number
of features so that we can

312
00:16:41,040 --> 00:16:44,010
actually finish our
computations?

313
00:16:44,010 --> 00:16:46,620
We've been using different kinds
of clustering, different

314
00:16:46,620 --> 00:16:51,140
kinds of supervised learning,
many different techniques.

315
00:16:51,140 --> 00:16:55,510
And we're beginning to get a
handle here on, in fact, what

316
00:16:55,510 --> 00:16:59,060
are some of the causes of these
infections and what

317
00:16:59,060 --> 00:17:00,770
could they be done.

318
00:17:00,770 --> 00:17:04,069
Some of the things are
very disturbing.

319
00:17:04,069 --> 00:17:07,200
Some of them, a lot of them,
seem to be caused by drugs

320
00:17:07,200 --> 00:17:09,480
that are given in
the hospital.

321
00:17:09,480 --> 00:17:12,050
And maybe we can substitute
one drug for another if we

322
00:17:12,050 --> 00:17:14,300
understand that.

323
00:17:14,300 --> 00:17:17,609
At least in some cases they seem
to be related to things

324
00:17:17,609 --> 00:17:24,300
like what room you happen to be
placed in, suggesting that

325
00:17:24,300 --> 00:17:26,490
maybe they're not cleaning
the rooms adequately.

326
00:17:26,490 --> 00:17:28,220
Things like that.

327
00:17:28,220 --> 00:17:30,020
All right.

328
00:17:30,020 --> 00:17:34,010
Another project, probably our
biggest sets of projects, have

329
00:17:34,010 --> 00:17:36,730
to do with extracting
information from

330
00:17:36,730 --> 00:17:39,040
physiological signals.

331
00:17:39,040 --> 00:17:41,590
We've been focusing on the
heart, the brain, and the

332
00:17:41,590 --> 00:17:43,240
connected anatomy.

333
00:17:43,240 --> 00:17:47,070
For those of you who don't
happen to be biology or course

334
00:17:47,070 --> 00:17:49,630
20 majors, here's where the
heart and the brain are

335
00:17:49,630 --> 00:17:53,030
located and what
they look like.

336
00:17:53,030 --> 00:17:57,340
Some of the examples we're
interested in are predicting

337
00:17:57,340 --> 00:18:01,440
adverse cardiac events.

338
00:18:01,440 --> 00:18:04,960
And for that you can think
about death from a heart

339
00:18:04,960 --> 00:18:06,760
event, heart attack.

340
00:18:06,760 --> 00:18:10,070
And we spent a lot of time
dealing with epilepsy.

341
00:18:10,070 --> 00:18:12,630
So let me give a little bit more
detail about these two

342
00:18:12,630 --> 00:18:15,560
examples because each of
them relate to things

343
00:18:15,560 --> 00:18:18,150
we've covered in 6.00.

344
00:18:18,150 --> 00:18:23,140
So epilepsy, an interesting
disease.

345
00:18:23,140 --> 00:18:30,210
Surprisingly, it affects about
1% of the world's population.

346
00:18:30,210 --> 00:18:33,030
When I first heard this,
I was astounded.

347
00:18:33,030 --> 00:18:35,250
Because gee, 1 out
of 100 people

348
00:18:35,250 --> 00:18:37,750
that I know have epilepsy?

349
00:18:37,750 --> 00:18:40,520
And the truth is, yes.

350
00:18:40,520 --> 00:18:42,180
I just didn't know it.

351
00:18:42,180 --> 00:18:44,830
I've been amazed, since it's
become known that I do

352
00:18:44,830 --> 00:18:47,700
research in this area, the
number of people I've known

353
00:18:47,700 --> 00:18:50,850
for years who come up to me
say, you know, I never

354
00:18:50,850 --> 00:18:54,390
mentioned this before, but I
have epilepsy, or my kid has

355
00:18:54,390 --> 00:18:57,560
epilepsy or my parent has
epilepsy, and I have some

356
00:18:57,560 --> 00:18:59,120
questions now that you're
supposed to be

357
00:18:59,120 --> 00:19:01,110
an expert on this.

358
00:19:01,110 --> 00:19:04,440
And I give them the usual
caveats, you know, I'm not a

359
00:19:04,440 --> 00:19:06,890
doctor, I just play
one on television.

360
00:19:06,890 --> 00:19:09,750
But then I tell them go talk
to one of my students.

361
00:19:09,750 --> 00:19:13,550
They're not doctors either,
but they're really smart.

362
00:19:13,550 --> 00:19:15,520
Probably smarter than
your doctor.

363
00:19:15,520 --> 00:19:16,770
All right.

364
00:19:19,260 --> 00:19:22,060
Why is it underestimated when
we do it ourselves?

365
00:19:22,060 --> 00:19:25,110
Well, because they're
still some stigmas.

366
00:19:25,110 --> 00:19:27,940
A few hundred years ago, they
burned women in Salem,

367
00:19:27,940 --> 00:19:30,870
Massachusetts, who had epilepsy
because they thought

368
00:19:30,870 --> 00:19:33,970
the seizures meant they were
possessed by the devil.

369
00:19:33,970 --> 00:19:37,420
Today, if you tell the Registry
of Motor Vehicles

370
00:19:37,420 --> 00:19:39,130
that you have epilepsy, they
won't let you drive an

371
00:19:39,130 --> 00:19:40,720
automobile.

372
00:19:40,720 --> 00:19:44,440
So people tend not
to announce it.

373
00:19:44,440 --> 00:19:48,370
What's it characterized by
is a recurrent seizure.

374
00:19:48,370 --> 00:19:52,780
A seizure is abnormal electrical
activity that

375
00:19:52,780 --> 00:19:56,060
originates and persists
in the brain.

376
00:19:56,060 --> 00:19:57,910
Number of causes.

377
00:19:57,910 --> 00:19:58,810
It can be acquired.

378
00:19:58,810 --> 00:20:00,380
It can be inherited.

379
00:20:00,380 --> 00:20:03,020
There's manifest different
symptoms.

380
00:20:03,020 --> 00:20:04,960
Most of them do not
look like what's

381
00:20:04,960 --> 00:20:08,250
portrayed on the Simpsons.

382
00:20:08,250 --> 00:20:11,035
Slightly more realistically,
and maybe more horrifying.

383
00:20:15,780 --> 00:20:20,950
Here's a picture of a young
girl, a movie, you're gonna

384
00:20:20,950 --> 00:20:23,500
see a seizure.

385
00:20:23,500 --> 00:20:25,930
It's not pleasant, I'm
gonna warn you.

386
00:20:25,930 --> 00:20:29,700
What I want you to notice
is two things.

387
00:20:29,700 --> 00:20:33,340
(1) She's all happy, and
the seizure seems

388
00:20:33,340 --> 00:20:35,600
to come out of nowhere.

389
00:20:35,600 --> 00:20:36,930
She doesn't expect it.

390
00:20:36,930 --> 00:20:38,460
She doesn't know she's
going to have.

391
00:20:38,460 --> 00:20:40,180
It just hits.

392
00:20:40,180 --> 00:20:41,765
That's very important.

393
00:20:41,765 --> 00:20:47,080
(2) She happened to be in the
clinic at the time wearing

394
00:20:47,080 --> 00:20:51,140
this funny looking cap, with
it has electrodes in it.

395
00:20:51,140 --> 00:20:53,420
Just sits on the scalp.

396
00:20:53,420 --> 00:20:56,310
And here is a record of the
electrical activity at the

397
00:20:56,310 --> 00:20:59,100
surface of her scalp.

398
00:20:59,100 --> 00:21:04,050
And what you'll see is a quick
slight change on it just

399
00:21:04,050 --> 00:21:07,950
before the seizure hits, and
then enormous changes during

400
00:21:07,950 --> 00:21:09,470
the seizure.

401
00:21:09,470 --> 00:21:11,730
Turns out that the enormous
changes during the seizure

402
00:21:11,730 --> 00:21:14,130
have nothing really to
do with the seizure.

403
00:21:14,130 --> 00:21:16,530
They have to do with
muscle activity.

404
00:21:16,530 --> 00:21:20,950
As you'll see once the seizure
hits, there's a lot of ugly

405
00:21:20,950 --> 00:21:21,890
muscle activity.

406
00:21:21,890 --> 00:21:22,220
All right.

407
00:21:22,220 --> 00:21:23,470
Let's look at it.

408
00:21:27,420 --> 00:21:29,040
Uh oh.

409
00:21:29,040 --> 00:21:30,290
All right.

410
00:21:33,390 --> 00:21:34,640
Let's look at it--

411
00:21:39,170 --> 00:21:41,670
I thought I had put the links in
here that should have done

412
00:21:41,670 --> 00:21:45,610
it, but who knows.

413
00:21:50,500 --> 00:21:51,750
I know where to find them.

414
00:22:10,604 --> 00:22:11,102
[VIDEO PLAYBACK]

415
00:22:11,102 --> 00:22:21,010
[SINGING IN FOREIGN LANGUAGE]

416
00:22:21,010 --> 00:22:34,212
[SPEAKING FOREIGN LANGUAGE]

417
00:22:34,212 --> 00:22:35,530
[END VIDEO PLAYBACK]

418
00:22:35,530 --> 00:22:38,630
PROFESSOR: So kind of scary.

419
00:22:38,630 --> 00:22:41,720
Certainly when I've been seeing
them actually happen,

420
00:22:41,720 --> 00:22:44,630
I've found it terrifying
to watch.

421
00:22:44,630 --> 00:22:46,875
That kind of-- it's called
a tonic-clonic seizure.

422
00:22:50,350 --> 00:22:53,830
They seem- I emphasize the word
'seem' -- unpredictable.

423
00:22:53,830 --> 00:22:56,250
The interesting thing about
these seizures, or an

424
00:22:56,250 --> 00:22:59,200
interesting thing, is they're
self-limiting.

425
00:22:59,200 --> 00:23:03,740
In a few minutes, that young
lady or girl's seizure will be

426
00:23:03,740 --> 00:23:07,040
over, not because anybody
intervened but because the

427
00:23:07,040 --> 00:23:09,300
brain resets itself.

428
00:23:09,300 --> 00:23:11,280
Then it will take--

429
00:23:11,280 --> 00:23:14,710
in this case, probably took her
about an hour to recover

430
00:23:14,710 --> 00:23:17,370
and get back to normal,
which is not good.

431
00:23:17,370 --> 00:23:21,070
But after that, everything was
as before the seizure.

432
00:23:21,070 --> 00:23:26,205
The difficulty is because
they're unpredictable, there

433
00:23:26,205 --> 00:23:28,040
are huge injuries.

434
00:23:28,040 --> 00:23:31,440
Imagine she'd been riding
a bicycle when that hit.

435
00:23:31,440 --> 00:23:33,620
Well, something catastrophic.

436
00:23:33,620 --> 00:23:37,010
Or more simply, imagine she'd
been going down a flight of

437
00:23:37,010 --> 00:23:40,410
stairs or in a bathtub.

438
00:23:40,410 --> 00:23:43,040
Any one of a number of things
would have resulted in this

439
00:23:43,040 --> 00:23:47,660
potentially catastrophic
collateral damage after the

440
00:23:47,660 --> 00:23:50,650
seizure or during the seizure.

441
00:23:50,650 --> 00:23:53,440
And indeed people who
have epilepsy, you

442
00:23:53,440 --> 00:23:56,520
can see their scars.

443
00:23:56,520 --> 00:23:57,890
It's awful.

444
00:23:57,890 --> 00:24:05,300
It can result in death, about
1 per 100 patient years.

445
00:24:05,300 --> 00:24:07,140
It's called the sudden
unexpected

446
00:24:07,140 --> 00:24:09,580
death in epilepsy patients.

447
00:24:09,580 --> 00:24:13,100
So what we wanted to do is see
whether we could detect the

448
00:24:13,100 --> 00:24:17,410
seizures and give a
little warning.

449
00:24:17,410 --> 00:24:19,940
The notion being that even if
you couldn't do anything about

450
00:24:19,940 --> 00:24:23,500
the seizure, if you could give
somebody, say, even five

451
00:24:23,500 --> 00:24:25,950
seconds warning, they
could sit down

452
00:24:25,950 --> 00:24:27,880
before they fell down.

453
00:24:27,880 --> 00:24:29,340
They could get out of the tub.

454
00:24:29,340 --> 00:24:31,130
They could back away
from the stove.

455
00:24:31,130 --> 00:24:33,050
All sorts of things.

456
00:24:33,050 --> 00:24:37,160
Furthermore, if you could use
technology to signal to

457
00:24:37,160 --> 00:24:39,560
someone else that there was
about to be a seizure, help

458
00:24:39,560 --> 00:24:40,740
could arrive.

459
00:24:40,740 --> 00:24:43,890
Also potentially a good thing.

460
00:24:43,890 --> 00:24:48,330
Turns out there are now some
fast-acting drugs that if you

461
00:24:48,330 --> 00:24:51,610
put under the tongue can
ameliorate the seizure.

462
00:24:51,610 --> 00:24:55,580
These have not yet been approved
by the FDA, but soon.

463
00:24:55,580 --> 00:24:57,530
And we were particularly
interested in neural

464
00:24:57,530 --> 00:24:59,370
stimulation.

465
00:24:59,370 --> 00:25:02,390
If we ejected electrical current
into the brain at

466
00:25:02,390 --> 00:25:06,130
exactly the right moment, could
we offset essentially

467
00:25:06,130 --> 00:25:09,010
the effect of the seizure
and do a reset?

468
00:25:09,010 --> 00:25:13,810
And maybe stop the seizure or
abort it, prevent it, or at

469
00:25:13,810 --> 00:25:19,280
least reduce the long
term recovery time.

470
00:25:19,280 --> 00:25:22,180
The thing to keep in mind for
the seizure is there were two

471
00:25:22,180 --> 00:25:25,020
distinct onset times.

472
00:25:25,020 --> 00:25:28,430
What you saw if you're looking
at the girl was what's called

473
00:25:28,430 --> 00:25:33,360
the clinical onset, when there's
some clinical event.

474
00:25:33,360 --> 00:25:36,650
If you were able to not look at
the person and instead look

475
00:25:36,650 --> 00:25:40,730
at the EEG, not so easy, you
would have seen that there was

476
00:25:40,730 --> 00:25:45,860
an electrographic onset that
preceded the clinical onset.

477
00:25:45,860 --> 00:25:48,970
We know, in fact, since the
clinical effects are caused by

478
00:25:48,970 --> 00:25:52,520
the electrical activity, there
will always be abnormal

479
00:25:52,520 --> 00:25:55,210
electrical activity
prior to any

480
00:25:55,210 --> 00:25:57,580
abnormal clinical activity.

481
00:25:57,580 --> 00:26:01,740
And so the hope was that we
could detect the electrical

482
00:26:01,740 --> 00:26:05,280
activity early.

483
00:26:05,280 --> 00:26:08,150
Now that's not so easy.

484
00:26:08,150 --> 00:26:12,690
What makes it hard is
that the EEG, the

485
00:26:12,690 --> 00:26:18,500
electroencephalograph, differs
greatly across patients.

486
00:26:18,500 --> 00:26:22,780
First of all, people with
epilepsy have abnormal

487
00:26:22,780 --> 00:26:24,860
baseline EEG.

488
00:26:24,860 --> 00:26:28,650
Even when they're not having a
seizure, bizarre things are

489
00:26:28,650 --> 00:26:29,960
going on in their brains

490
00:26:29,960 --> 00:26:32,590
electrically, all unusual things.

491
00:26:32,590 --> 00:26:35,640
And so they don't
look like people

492
00:26:35,640 --> 00:26:38,840
who don't have epilepsy.

493
00:26:38,840 --> 00:26:44,040
And it varies tremendously
across patients.

494
00:26:44,040 --> 00:26:47,770
So for about 35 years, people
attempted to build generic

495
00:26:47,770 --> 00:26:51,470
detectors that would detect
seizures in everybody.

496
00:26:51,470 --> 00:26:54,290
And they've not worked
well at all.

497
00:26:54,290 --> 00:26:58,160
Every time a hospital buys an
EEG machine, it comes with a

498
00:26:58,160 --> 00:26:59,760
detector built in.

499
00:26:59,760 --> 00:27:03,380
And usually the first thing they
do is they turn them off

500
00:27:03,380 --> 00:27:07,340
because the false alarm rate is
so high that it's like the

501
00:27:07,340 --> 00:27:09,330
boy who cried wolf.

502
00:27:09,330 --> 00:27:12,150
They're just saying seizure,
seizure, seizure, and people

503
00:27:12,150 --> 00:27:14,870
start ignoring it.

504
00:27:14,870 --> 00:27:19,530
The good news is it's pretty
consistent seizure onset for a

505
00:27:19,530 --> 00:27:21,750
particular individual.

506
00:27:21,750 --> 00:27:25,240
That suggests you should build
not generic detectors, but

507
00:27:25,240 --> 00:27:28,410
patient specific detectors.

508
00:27:28,410 --> 00:27:30,370
And we've been working
on using machine

509
00:27:30,370 --> 00:27:32,720
learning to do that.

510
00:27:32,720 --> 00:27:35,880
And in fact, it's been
highly successful.

511
00:27:35,880 --> 00:27:38,530
We've done several retrospective
studies

512
00:27:38,530 --> 00:27:41,590
indicating that it works
really well.

513
00:27:41,590 --> 00:27:43,760
And we're now doing
a substantial

514
00:27:43,760 --> 00:27:46,240
prospective study --

515
00:27:46,240 --> 00:27:48,970
in progress at MGH.

516
00:27:48,970 --> 00:27:53,590
And as part of that, we're
actually working at turning on

517
00:27:53,590 --> 00:27:58,770
a neuro-stimulator that we hope
will attenuate the effect

518
00:27:58,770 --> 00:28:00,020
of the seizure.

519
00:28:00,020 --> 00:28:02,440
And I emphasize hope because we
don't have enough data to

520
00:28:02,440 --> 00:28:05,180
know if it works.

521
00:28:05,180 --> 00:28:07,700
It's part of what goes
on in this business.

522
00:28:07,700 --> 00:28:10,280
But it's certainly been an
interesting project.

523
00:28:10,280 --> 00:28:10,730
All right.

524
00:28:10,730 --> 00:28:11,980
Heart attacks.

525
00:28:14,850 --> 00:28:15,750
Let's look at that.

526
00:28:15,750 --> 00:28:18,850
And I'll go to the easy
way to show them.

527
00:28:18,850 --> 00:28:25,720
I should warn you, you're gonna
see something that's not

528
00:28:25,720 --> 00:28:26,460
very pleasant.

529
00:28:26,460 --> 00:28:28,760
You're actually gonna
see somebody die.

530
00:28:31,730 --> 00:28:37,520
This was actually a person who
was playing in a soccer game

531
00:28:37,520 --> 00:28:39,800
and died while the game
was being televised.

532
00:28:43,330 --> 00:28:43,760
All right.

533
00:28:43,760 --> 00:28:50,060
What I want to show you is this
didn't have to happen.

534
00:28:50,060 --> 00:28:53,700
We're now gonna see another
televised soccer game where

535
00:28:53,700 --> 00:28:58,340
the player had exactly the same
event but with a rather

536
00:28:58,340 --> 00:28:59,590
different outcome.

537
00:29:03,700 --> 00:29:06,240
So look at the upper center of
field and you'll see the

538
00:29:06,240 --> 00:29:11,820
person has collapsed, much the
same way it happened before.

539
00:29:11,820 --> 00:29:13,980
Now watch the body convulse.

540
00:29:13,980 --> 00:29:17,200
You'll see the knees
kick up there.

541
00:29:17,200 --> 00:29:18,450
And now comes the miracle.

542
00:29:21,680 --> 00:29:22,930
He sits up.

543
00:29:25,520 --> 00:29:29,980
He leaves the field and, in
fact, he later asked if he can

544
00:29:29,980 --> 00:29:32,060
reenter the game.

545
00:29:32,060 --> 00:29:35,435
The coach, to the coach's
everlasting credit, said no.

546
00:29:38,020 --> 00:29:40,020
Clearly the right decision.

547
00:29:40,020 --> 00:29:47,000
So it's amazing really
that this happens.

548
00:29:47,000 --> 00:29:48,890
So what was the difference
between the two?

549
00:29:52,620 --> 00:29:56,540
well, we see this here.

550
00:29:56,540 --> 00:29:58,790
There are things you can do.

551
00:29:58,790 --> 00:30:04,370
So in acute coronary syndrome,
think of it as some sort of a

552
00:30:04,370 --> 00:30:05,040
heart attack.

553
00:30:05,040 --> 00:30:08,300
They're very common, about
one and a quarter million

554
00:30:08,300 --> 00:30:10,500
per year in the US.

555
00:30:10,500 --> 00:30:14,140
15% to 20% of these people will
suffer a cardiac-related

556
00:30:14,140 --> 00:30:16,700
death within the next
four years.

557
00:30:16,700 --> 00:30:20,400
If you could figure out who
were the people at highest

558
00:30:20,400 --> 00:30:27,200
risk of different events and
choose the treatment properly,

559
00:30:27,200 --> 00:30:29,950
for example, implant an
implantable cardiac

560
00:30:29,950 --> 00:30:33,710
defibrillator, you could
save these lives.

561
00:30:33,710 --> 00:30:36,840
And that was what we
saw in our movies.

562
00:30:36,840 --> 00:30:41,180
That the first patient, first
person, the one who died, did

563
00:30:41,180 --> 00:30:43,580
not have a defibrillator.

564
00:30:43,580 --> 00:30:46,960
The second person, the one
who survived, did.

565
00:30:46,960 --> 00:30:49,280
So he collapsed on the field.

566
00:30:49,280 --> 00:30:55,440
The defibrillator sensed that
his heart had stopped, gave it

567
00:30:55,440 --> 00:30:56,470
an electric shock.

568
00:30:56,470 --> 00:30:58,430
You've all seen this in
television where they put the

569
00:30:58,430 --> 00:31:00,860
paddles on and they
say, clear.

570
00:31:00,860 --> 00:31:03,410
And then there's this moment of
drama where everyone stares

571
00:31:03,410 --> 00:31:06,870
at the EKG machine, and it
goes from a flat line to

572
00:31:06,870 --> 00:31:10,430
suddenly up and down, and
everyone goes, ah.

573
00:31:10,430 --> 00:31:12,550
Well that's exactly what
happened here.

574
00:31:12,550 --> 00:31:16,100
And that convulsion was this
huge electrical shock getting

575
00:31:16,100 --> 00:31:20,270
sent through the person's body
which restarted the heart,

576
00:31:20,270 --> 00:31:22,250
saved his life.

577
00:31:22,250 --> 00:31:26,260
Probably, if the other player
had had an ICD, he would not

578
00:31:26,260 --> 00:31:28,160
have died either.

579
00:31:28,160 --> 00:31:30,810
So great technology.

580
00:31:30,810 --> 00:31:34,280
Well, yes and no.

581
00:31:34,280 --> 00:31:36,740
This was a study in the New
England Journal of Medicine

582
00:31:36,740 --> 00:31:41,490
not so long ago, a very good
control study, where they

583
00:31:41,490 --> 00:31:46,500
matched patients with ICDs and
patients without ICDs and over

584
00:31:46,500 --> 00:31:52,070
72 months tracked which ones
lived and which ones died.

585
00:31:52,070 --> 00:31:55,610
Well, the disturbing news is
there isn't much difference

586
00:31:55,610 --> 00:31:57,120
between the red line
and the blue line.

587
00:31:59,660 --> 00:32:04,300
So these people had what was
essentially a, well, which was

588
00:32:04,300 --> 00:32:09,830
about a $50,000 implant and
various kinds of risks and

589
00:32:09,830 --> 00:32:13,560
inconvenience and discomfort,
et cetera, and on average it

590
00:32:13,560 --> 00:32:14,810
didn't save lives.

591
00:32:17,120 --> 00:32:19,490
Oh, dear.

592
00:32:19,490 --> 00:32:23,030
In fact, 90% of the people who
got them-- and this is not

593
00:32:23,030 --> 00:32:24,360
just in this study.

594
00:32:24,360 --> 00:32:28,050
This is in every study- receives
zero, actually less

595
00:32:28,050 --> 00:32:31,430
than zero medical benefit
from the ICD.

596
00:32:31,430 --> 00:32:33,040
How do we know that?

597
00:32:33,040 --> 00:32:35,540
Well, remember, it only turns on
when it senses the heart is

598
00:32:35,540 --> 00:32:37,130
in trouble.

599
00:32:37,130 --> 00:32:40,980
For 90% of the people who get
it, it never energizes because

600
00:32:40,980 --> 00:32:43,776
the heart doesn't
get in trouble,

601
00:32:43,776 --> 00:32:45,920
or detectable trouble.

602
00:32:45,920 --> 00:32:51,080
So what we see, if we look at
a little more detail in this

603
00:32:51,080 --> 00:32:58,850
study, is that for sudden
cardiac death, the kind of

604
00:32:58,850 --> 00:33:03,990
death we saw in those videos,
or non-death,

605
00:33:03,990 --> 00:33:07,890
the ICD reduces that.

606
00:33:07,890 --> 00:33:12,310
Unfortunately, it increases
other causes of death, for

607
00:33:12,310 --> 00:33:17,180
example, infections related to
the surgery, et cetera, those

608
00:33:17,180 --> 00:33:19,900
unfortunate hospital acquired
infections, for example, we

609
00:33:19,900 --> 00:33:21,740
talked about earlier.

610
00:33:21,740 --> 00:33:26,980
So what we see here is we have
a technology that if we knew

611
00:33:26,980 --> 00:33:31,690
whose heart was likely to
stop or go into serious

612
00:33:31,690 --> 00:33:35,070
fibrillation, beating
uncontrollably, and we only

613
00:33:35,070 --> 00:33:38,560
gave those people ICDs,
we could save an

614
00:33:38,560 --> 00:33:41,740
enormous number of lives.

615
00:33:41,740 --> 00:33:45,350
But currently we don't know
who's in that population, and

616
00:33:45,350 --> 00:33:47,600
therefore we don't know
who should get them.

617
00:33:47,600 --> 00:33:51,240
So we use other mechanisms
deciding who should get them.

618
00:33:51,240 --> 00:33:54,840
And we're wrong most of the
time, doing more harm than

619
00:33:54,840 --> 00:33:58,770
good on those patients
for whom we're wrong.

620
00:33:58,770 --> 00:33:59,280
OK.

621
00:33:59,280 --> 00:34:02,960
Well, how do the people
predict it today?

622
00:34:02,960 --> 00:34:04,500
The usual things.

623
00:34:04,500 --> 00:34:05,490
Are you male or female?

624
00:34:05,490 --> 00:34:06,930
Do you have high
blood pressure?

625
00:34:06,930 --> 00:34:07,730
Diabetes?

626
00:34:07,730 --> 00:34:09,889
What's your cholesterol level?

627
00:34:09,889 --> 00:34:10,550
BMP?

628
00:34:10,550 --> 00:34:12,960
Various other kinds of things.

629
00:34:12,960 --> 00:34:16,360
Electrocardiograms,
which look at--

630
00:34:16,360 --> 00:34:18,900
it's an echo cardiogram
that looks at the

631
00:34:18,900 --> 00:34:19,909
activity of the heart.

632
00:34:19,909 --> 00:34:22,770
Is the blood flowing
through it OK?

633
00:34:22,770 --> 00:34:23,840
EKGs.

634
00:34:23,840 --> 00:34:26,719
Many different methods for
analyzing the electrical

635
00:34:26,719 --> 00:34:28,360
activity, et cetera.

636
00:34:31,429 --> 00:34:34,260
We played with many of
these techniques.

637
00:34:34,260 --> 00:34:36,429
The one I want to tell you about
today, because it's the

638
00:34:36,429 --> 00:34:40,360
most closely related to 6.00
material, is what we think of

639
00:34:40,360 --> 00:34:43,580
the Tolstoy approach to
risk stratification.

640
00:34:43,580 --> 00:34:47,400
So Tolstoy is famous for saying
that happy families are

641
00:34:47,400 --> 00:34:50,550
all alike, but every
unhappy family is

642
00:34:50,550 --> 00:34:53,699
unhappy in its own way.

643
00:34:53,699 --> 00:34:58,440
So we generalize that, or
specialized it maybe, to say

644
00:34:58,440 --> 00:35:01,320
that happy hearts are all alike,
but every unhappy heart

645
00:35:01,320 --> 00:35:05,200
is different, and then did some
fairly simple work to

646
00:35:05,200 --> 00:35:10,310
quantify the difference between
electrical activities

647
00:35:10,310 --> 00:35:17,250
in different people's hearts,
converting it to symbols.

648
00:35:17,250 --> 00:35:19,330
You don't have to worry
about that.

649
00:35:19,330 --> 00:35:22,470
We used dynamic programming as
an important part because we

650
00:35:22,470 --> 00:35:24,920
were looking at roughly a
billion heart beats and so we

651
00:35:24,920 --> 00:35:28,000
needed to make it run fast.

652
00:35:28,000 --> 00:35:33,070
And then we used clustering to
identify patients whose hearts

653
00:35:33,070 --> 00:35:37,170
we thought were similar
to one another.

654
00:35:37,170 --> 00:35:39,340
Here are some results.

655
00:35:39,340 --> 00:35:42,590
These are people who had an
acute coronary syndrome.

656
00:35:42,590 --> 00:35:46,480
So the dominant group, the
biggest group, the quote

657
00:35:46,480 --> 00:35:49,200
"people who we thought were
most likely to be fine"--

658
00:35:49,200 --> 00:35:51,190
because remember, most
people are fine

659
00:35:51,190 --> 00:35:53,830
after a heart attack--

660
00:35:53,830 --> 00:35:58,880
457 patients in this particular
data set.

661
00:35:58,880 --> 00:36:02,960
And you can see that they
did pretty well.

662
00:36:02,960 --> 00:36:07,300
A very small fraction
of them died.

663
00:36:07,300 --> 00:36:09,560
Can't see it from this angle,
but come out here.

664
00:36:09,560 --> 00:36:12,410
Yeah, less than 1%.

665
00:36:12,410 --> 00:36:14,480
But then we looked at
people who were

666
00:36:14,480 --> 00:36:15,710
in these other clusters.

667
00:36:15,710 --> 00:36:19,000
And in fact, we used a glomerate
of hierarchical

668
00:36:19,000 --> 00:36:21,276
clustering to do this.

669
00:36:21,276 --> 00:36:27,890
And in cluster A, which had 53
patients, well, 3.77% died.

670
00:36:27,890 --> 00:36:31,475
If you happened to fall
in cluster C, you were

671
00:36:31,475 --> 00:36:32,725
at very high risk.

672
00:36:35,270 --> 00:36:38,130
And we can just see that there's
a big difference here.

673
00:36:38,130 --> 00:36:43,340
And so the notion is could we
have used this to predict in

674
00:36:43,340 --> 00:36:48,660
advance who was most likely to
benefit from the various kinds

675
00:36:48,660 --> 00:36:50,020
of treatments?

676
00:36:50,020 --> 00:36:50,500
All right.

677
00:36:50,500 --> 00:36:54,020
Again, very quick just to
give you the details--

678
00:36:54,020 --> 00:36:57,325
not the details, the overview
that the kinds of things that

679
00:36:57,325 --> 00:37:01,610
we cover in this course are
actually quite useful in

680
00:37:01,610 --> 00:37:04,510
solving real practical
problems.

681
00:37:04,510 --> 00:37:06,060
All right.

682
00:37:06,060 --> 00:37:07,310
Let me wrap up the term.

683
00:37:09,890 --> 00:37:14,640
So I hope most of you feel
you've come a long way--

684
00:37:14,640 --> 00:37:15,925
maybe you prefer this picture.

685
00:37:22,640 --> 00:37:26,810
That if you think about the
kinds of problems and

686
00:37:26,810 --> 00:37:31,500
struggles you had three months
ago in getting tiny little

687
00:37:31,500 --> 00:37:34,990
programs to work and think about
how easy those would be

688
00:37:34,990 --> 00:37:38,300
for you today, you should have
some appreciation that you've

689
00:37:38,300 --> 00:37:41,770
really taught yourself a lot.

690
00:37:41,770 --> 00:37:44,690
And you really taught it to
yourself, by doing the problem

691
00:37:44,690 --> 00:37:46,540
sets, in many ways, right.

692
00:37:46,540 --> 00:37:50,700
We've tried to help, but
learning is very much up to

693
00:37:50,700 --> 00:37:53,580
the individual who's
doing the learning.

694
00:37:53,580 --> 00:37:58,120
But I'm certainly impressed in
looking at the kinds of really

695
00:37:58,120 --> 00:38:00,745
pretty complicated problems
you guys can now solve.

696
00:38:03,400 --> 00:38:06,890
We looked at six major topics.

697
00:38:06,890 --> 00:38:09,910
Clearly, you learned a notation
for expressing

698
00:38:09,910 --> 00:38:13,220
computations, and
that was Python.

699
00:38:13,220 --> 00:38:16,660
And I hope you don't think
that's the only notation you

700
00:38:16,660 --> 00:38:20,100
can use and that if you take
a course that uses MATLAB,

701
00:38:20,100 --> 00:38:21,720
you'll say, oh, this
is just the same.

702
00:38:21,720 --> 00:38:22,300
It's easy.

703
00:38:22,300 --> 00:38:24,560
Or Java or anything else.

704
00:38:24,560 --> 00:38:27,080
Learning programming
languages is easy.

705
00:38:27,080 --> 00:38:31,450
Once you've learned one, the
next one is much easier.

706
00:38:31,450 --> 00:38:34,410
Harder was learning about the
process of writing and

707
00:38:34,410 --> 00:38:35,660
debugging programs.

708
00:38:38,460 --> 00:38:41,590
You've learned that, I think,
largely through experience.

709
00:38:41,590 --> 00:38:44,960
You've learned about the process
of moving from a

710
00:38:44,960 --> 00:38:49,960
problem statement, something
as vague as should shuttle

711
00:38:49,960 --> 00:38:54,650
buses be bigger or faster
to improve service, to a

712
00:38:54,650 --> 00:38:58,980
computational formulation of the
problem and a method for

713
00:38:58,980 --> 00:39:00,480
solving a problem.

714
00:39:00,480 --> 00:39:04,560
And we've looked at lots
of different methods.

715
00:39:04,560 --> 00:39:07,700
You've learned basic recipes,
algorithms, things like

716
00:39:07,700 --> 00:39:10,480
dynamic programming, things
like depth-first search,

717
00:39:10,480 --> 00:39:13,690
things like decision trees,
that you'll be able to use

718
00:39:13,690 --> 00:39:15,010
again and again.

719
00:39:15,010 --> 00:39:17,920
The good news is there are only
a really small number of

720
00:39:17,920 --> 00:39:19,800
important recipes.

721
00:39:19,800 --> 00:39:22,540
And once you've mastered those,
you just use them over

722
00:39:22,540 --> 00:39:27,860
and over again to solve
new problems.

723
00:39:27,860 --> 00:39:32,720
Spent a lot of time on using
simulations to shed light on

724
00:39:32,720 --> 00:39:34,960
problems that don't
easily succumb

725
00:39:34,960 --> 00:39:38,200
to closed form solutions.

726
00:39:38,200 --> 00:39:40,310
And I think that's really
the place where

727
00:39:40,310 --> 00:39:43,500
computation is so important.

728
00:39:43,500 --> 00:39:45,820
There are a lot of problems
where you can turn them into a

729
00:39:45,820 --> 00:39:49,800
set of differential equations,
maybe solve the equations, and

730
00:39:49,800 --> 00:39:50,980
you're done.

731
00:39:50,980 --> 00:39:54,300
Oh, we'll write programs to do
those because we're lazy.

732
00:39:54,300 --> 00:39:55,850
But in principle,
you could solve

733
00:39:55,850 --> 00:39:58,920
those without a computer.

734
00:39:58,920 --> 00:40:02,650
But in fact, the thing you can't
do without a computer is

735
00:40:02,650 --> 00:40:05,450
these messy problems that are
most of what goes on in the

736
00:40:05,450 --> 00:40:08,860
real world, where there's
randomness, and things like

737
00:40:08,860 --> 00:40:10,920
that, and there is no
simple formula that

738
00:40:10,920 --> 00:40:12,390
gives you the answer.

739
00:40:12,390 --> 00:40:15,390
And what you have to do is write
a simulation and run it

740
00:40:15,390 --> 00:40:17,580
and see what goes on.

741
00:40:17,580 --> 00:40:20,730
And that's why we spent so
much time on simulation

742
00:40:20,730 --> 00:40:23,280
because it really is
increasingly the

743
00:40:23,280 --> 00:40:25,380
thing people use.

744
00:40:25,380 --> 00:40:29,540
And we learned about how to
use computational tools to

745
00:40:29,540 --> 00:40:35,820
help model and understand data,
how to do [?] plots, a

746
00:40:35,820 --> 00:40:39,110
small amount of statistics,
machine learning, just

747
00:40:39,110 --> 00:40:41,690
dealing with data.

748
00:40:41,690 --> 00:40:44,310
Why Python?

749
00:40:44,310 --> 00:40:46,530
It's pretty easy to
learn to use.

750
00:40:46,530 --> 00:40:48,860
Compared to most other
programming languages like,

751
00:40:48,860 --> 00:40:53,280
say, C++ or Java,
Python is easy.

752
00:40:53,280 --> 00:40:55,710
The syntax is simple.

753
00:40:55,710 --> 00:40:58,820
It's interpretive, which
makes debugging easier.

754
00:40:58,820 --> 00:41:02,070
You don't have to worry about
managing memory as you do in,

755
00:41:02,070 --> 00:41:03,220
say, C, right.

756
00:41:03,220 --> 00:41:05,670
You get a big list or
dictionary, and

757
00:41:05,670 --> 00:41:07,210
magically it exists.

758
00:41:07,210 --> 00:41:10,610
And when you don't need it
any more, it's gone.

759
00:41:10,610 --> 00:41:12,220
It's modern.

760
00:41:12,220 --> 00:41:16,280
It supports the currently
stylish mode of

761
00:41:16,280 --> 00:41:21,240
object-oriented programming in
a nice way with its classes

762
00:41:21,240 --> 00:41:22,520
and things like that.

763
00:41:22,520 --> 00:41:25,920
So indeed what you would hear
about in a Java class, we can

764
00:41:25,920 --> 00:41:27,780
cover almost all the

765
00:41:27,780 --> 00:41:30,170
interesting things with Python.

766
00:41:30,170 --> 00:41:33,240
And it's increasingly popular.

767
00:41:33,240 --> 00:41:37,100
It's used in an increasing
number of subjects at MIT.

768
00:41:37,100 --> 00:41:40,360
A lot of course 6 subjects, but
also a lot of course 20

769
00:41:40,360 --> 00:41:43,950
subjects, course 9 subjects,
over and over again.

770
00:41:43,950 --> 00:41:48,000
It's becoming, probably, the
most popular language at MIT

771
00:41:48,000 --> 00:41:50,710
and at other universities.

772
00:41:50,710 --> 00:41:53,090
Increasingly it's used
in industry.

773
00:41:53,090 --> 00:41:57,590
And as you've seen with PyLab,
the libraries are amazing.

774
00:41:57,590 --> 00:42:01,660
And so PyLab, Random, et cetera,
there's just a lot of

775
00:42:01,660 --> 00:42:03,790
stuff you can get for free
if you're living in

776
00:42:03,790 --> 00:42:05,040
the world of Python.

777
00:42:07,800 --> 00:42:10,790
The main thing in writing,
testing, and bugging programs,

778
00:42:10,790 --> 00:42:14,640
I hope you've learned, is to
take it a step at a time.

779
00:42:14,640 --> 00:42:16,560
Understand the problem.

780
00:42:16,560 --> 00:42:19,660
Think about the overall
structure and algorithms

781
00:42:19,660 --> 00:42:23,410
separately of how you express
them in the programming

782
00:42:23,410 --> 00:42:24,980
language, right.

783
00:42:24,980 --> 00:42:28,340
We can talk about dynamic
programming conceptually

784
00:42:28,340 --> 00:42:31,280
without worrying about
how to code it up.

785
00:42:31,280 --> 00:42:34,160
Always break the problem
into small parts.

786
00:42:34,160 --> 00:42:37,160
Identify useful abstractions.

787
00:42:37,160 --> 00:42:41,630
Code and test each unit
independently.

788
00:42:41,630 --> 00:42:44,260
Worry about functionality
first.

789
00:42:44,260 --> 00:42:45,270
Get it to work.

790
00:42:45,270 --> 00:42:46,540
Get it to give you
the right answer.

791
00:42:46,540 --> 00:42:49,980
Then worry about making it
do that more quickly.

792
00:42:49,980 --> 00:42:52,880
But separate those things.

793
00:42:52,880 --> 00:42:54,230
Start with some pseudo code.

794
00:42:57,150 --> 00:43:01,220
Then above all, be systematic.

795
00:43:01,220 --> 00:43:04,990
When debugging, think about
the scientific method of

796
00:43:04,990 --> 00:43:09,610
forming hypotheses, forming
experiments that can test the

797
00:43:09,610 --> 00:43:12,110
hypotheses, running
the experiment,

798
00:43:12,110 --> 00:43:13,980
checking the results.

799
00:43:13,980 --> 00:43:16,250
Don't try and do
it too quickly.

800
00:43:16,250 --> 00:43:17,890
Just be slow and careful.

801
00:43:17,890 --> 00:43:21,400
Slow and steady will win
the race in debugging.

802
00:43:21,400 --> 00:43:24,890
And when your program
behaves badly--

803
00:43:24,890 --> 00:43:29,165
and the sad news is no matter
how many years you spend at

804
00:43:29,165 --> 00:43:31,850
it, you will write programs that
don't work the way you

805
00:43:31,850 --> 00:43:34,830
think they should
the first time--

806
00:43:34,830 --> 00:43:38,670
ask yourself why it did what it
did, not why didn't it do

807
00:43:38,670 --> 00:43:40,560
what you wanted to do.

808
00:43:40,560 --> 00:43:43,960
It's a lot easier to debug
from the how come it's

809
00:43:43,960 --> 00:43:46,740
behaving the way it is then why
isn't it behaving the way

810
00:43:46,740 --> 00:43:47,990
I want it to behave.

811
00:43:50,280 --> 00:43:53,130
In going from problem statement
to computation,

812
00:43:53,130 --> 00:43:55,860
break the problem into
smaller problems.

813
00:43:55,860 --> 00:43:59,240
Try and relate your problem to
a problem that somebody else,

814
00:43:59,240 --> 00:44:01,420
ideally, has already solved.

815
00:44:01,420 --> 00:44:03,430
For example, is it a
knapsack problem?

816
00:44:03,430 --> 00:44:05,430
Is it a shortest path problem?

817
00:44:05,430 --> 00:44:10,030
If so, good, I know how
to solve those.

818
00:44:10,030 --> 00:44:12,460
Think about what kind of output
you might want to see.

819
00:44:12,460 --> 00:44:13,880
What should the plots be like?

820
00:44:13,880 --> 00:44:18,250
I usually design the output
before I design the program.

821
00:44:18,250 --> 00:44:22,640
Often you can formulate things
as an optimization problem.

822
00:44:22,640 --> 00:44:23,700
Pull back.

823
00:44:23,700 --> 00:44:26,710
Say, well, can I formulate this
as finding the minimum or

824
00:44:26,710 --> 00:44:31,040
maximum values satisfying an
objective function and some

825
00:44:31,040 --> 00:44:33,070
set of constraints?

826
00:44:33,070 --> 00:44:36,790
If I can, it's an optimization
problem, and therefore I know

827
00:44:36,790 --> 00:44:39,490
how to attack it.

828
00:44:39,490 --> 00:44:44,830
And don't be afraid to think
about approximate solutions.

829
00:44:44,830 --> 00:44:47,870
Sometimes you're just gonna not
actually be able to solve

830
00:44:47,870 --> 00:44:49,950
the problem you want to solve.

831
00:44:49,950 --> 00:44:53,010
And so you'll find a solution to
a simpler problem, and that

832
00:44:53,010 --> 00:44:54,740
will be good enough.

833
00:44:54,740 --> 00:44:58,330
Sometimes you can actually solve
the problem by finding a

834
00:44:58,330 --> 00:45:01,470
series of solutions that
approaches, but may never

835
00:45:01,470 --> 00:45:03,740
reach, a perfect answer.

836
00:45:03,740 --> 00:45:06,130
Probably the third week in the
course, we looked at Newton's

837
00:45:06,130 --> 00:45:11,190
method as an example of
that kind of problem.

838
00:45:11,190 --> 00:45:12,340
And then there are algorithms.

839
00:45:12,340 --> 00:45:17,210
We looked at big O notation,
various kinds of algorithms, a

840
00:45:17,210 --> 00:45:17,990
lot of kinds.

841
00:45:17,990 --> 00:45:21,450
You've already - I sent a list
of specific algorithms.

842
00:45:21,450 --> 00:45:25,780
And particularly, we looked
at optimization problems.

843
00:45:25,780 --> 00:45:29,200
We spent a lot of time on
modeling the world, keeping in

844
00:45:29,200 --> 00:45:31,850
mind that the models
are always wrong.

845
00:45:31,850 --> 00:45:36,290
But nevertheless, they're
often useful.

846
00:45:36,290 --> 00:45:38,520
They provide abstractions
of reality.

847
00:45:38,520 --> 00:45:42,400
So we looked at two kinds of
simulation models, Monte Carlo

848
00:45:42,400 --> 00:45:44,220
and queuing networks.

849
00:45:44,220 --> 00:45:47,040
We looked at statistical models,
for example, linear

850
00:45:47,040 --> 00:45:48,150
regression.

851
00:45:48,150 --> 00:45:50,880
And we looked at some graph
theoretic models.

852
00:45:50,880 --> 00:45:53,840
Those are not the only
techniques, but they're very

853
00:45:53,840 --> 00:45:55,090
useful techniques.

854
00:45:58,180 --> 00:45:59,880
We looked at making
sense of data.

855
00:45:59,880 --> 00:46:02,710
We talked about statistical
techniques.

856
00:46:02,710 --> 00:46:03,900
How to use them well.

857
00:46:03,900 --> 00:46:07,180
How to use them badly.

858
00:46:07,180 --> 00:46:08,270
We looked at plotting.

859
00:46:08,270 --> 00:46:11,023
And we spent some time on
machine learning, supervised

860
00:46:11,023 --> 00:46:16,080
and unsupervised and feature
vectors, and spent a lot of

861
00:46:16,080 --> 00:46:19,700
time talking about how do you
choose the features, because

862
00:46:19,700 --> 00:46:23,370
fundamentally that's typically
the difference between success

863
00:46:23,370 --> 00:46:27,640
and failure in the world
of machine learning.

864
00:46:27,640 --> 00:46:31,530
Throughout it all, the pervasive
themes were the

865
00:46:31,530 --> 00:46:36,790
power of abstraction and
systematic problem solving.

866
00:46:36,790 --> 00:46:39,900
So what's next?

867
00:46:39,900 --> 00:46:42,580
Many of you have worked really
hard this semester.

868
00:46:42,580 --> 00:46:43,290
We know that.

869
00:46:43,290 --> 00:46:47,650
And the TAs and LAs and
I all appreciate that.

870
00:46:47,650 --> 00:46:50,240
And I thank you sincerely
for the effort you

871
00:46:50,240 --> 00:46:52,540
put into the course.

872
00:46:52,540 --> 00:46:54,870
Only you know your return
on the investment.

873
00:46:54,870 --> 00:46:57,690
I hope it's good.

874
00:46:57,690 --> 00:47:00,500
Remember as you go forward in
your careers that you can now

875
00:47:00,500 --> 00:47:04,160
write programs to solve problems
you need to solve.

876
00:47:04,160 --> 00:47:06,130
Don't be afraid to do it.

877
00:47:06,130 --> 00:47:08,870
If you like this, there are
plenty of other CS courses

878
00:47:08,870 --> 00:47:10,630
that you now could take.

879
00:47:10,630 --> 00:47:13,500
You're actually equipped,
probably, to take any one of

880
00:47:13,500 --> 00:47:18,080
these four courses based upon
what you've learned in 6.00.

881
00:47:18,080 --> 00:47:21,210
You could major in course 6 or
think about the new major in

882
00:47:21,210 --> 00:47:23,950
computer science and
molecular biology.

883
00:47:23,950 --> 00:47:27,290
And you're certainly qualified
to go off and to look for

884
00:47:27,290 --> 00:47:31,010
UROPs that involve serious
programming.

885
00:47:31,010 --> 00:47:31,870
All right.

886
00:47:31,870 --> 00:47:35,630
Wrapping up with some famous
last words, these were words

887
00:47:35,630 --> 00:47:39,630
that some famous people said
as they were about to die.

888
00:47:39,630 --> 00:47:44,490
An actor, Douglas Fairbanks
senior, was asked by a family

889
00:47:44,490 --> 00:47:45,570
member, how are you feeling?

890
00:47:45,570 --> 00:47:47,240
He said, never felt better.

891
00:47:47,240 --> 00:47:51,430
And then that was the last
thing he ever said.

892
00:47:51,430 --> 00:47:54,670
In contrast, the last thing
Luther Burbank was reported to

893
00:47:54,670 --> 00:47:59,350
have said, a famous scientist,
was, I don't feel so good.

894
00:47:59,350 --> 00:48:01,010
He was a scientist rather
than actor.

895
00:48:01,010 --> 00:48:05,140
He had a better appreciation
of the state of the world.

896
00:48:05,140 --> 00:48:07,960
Conrad Hilton, who you probably
think of as Paris

897
00:48:07,960 --> 00:48:11,780
Hilton's grandfather, but
actually is more well known in

898
00:48:11,780 --> 00:48:17,080
some circles for running the
Hilton hotels, his last words

899
00:48:17,080 --> 00:48:19,530
when his family asked him-- they
knew he was dying-- is

900
00:48:19,530 --> 00:48:20,720
there anything you
want us to know

901
00:48:20,720 --> 00:48:22,430
about running the business?

902
00:48:22,430 --> 00:48:24,780
And he said, yes, leave the
shower curtain on the inside

903
00:48:24,780 --> 00:48:26,940
of the tub.

904
00:48:26,940 --> 00:48:30,090
And that's advice, I have to
confess, my wife has given me

905
00:48:30,090 --> 00:48:31,340
on several occasions.

906
00:48:33,570 --> 00:48:40,050
Archimedes, basically before
he was taken away and

907
00:48:40,050 --> 00:48:43,280
executed, asked, could he please
finish solving the

908
00:48:43,280 --> 00:48:45,080
problem he was working on.

909
00:48:45,080 --> 00:48:48,230
You know, I could imagine some
poor 6.00 student who's about

910
00:48:48,230 --> 00:48:50,970
to be carted away by the police
saying, can I finish my

911
00:48:50,970 --> 00:48:53,250
problem set first, please?

912
00:48:53,250 --> 00:48:55,910
Actually, I can't
imagine that.

913
00:48:55,910 --> 00:49:01,450
And finally, this US Civil War
general, John Sedgwick, was

914
00:49:01,450 --> 00:49:02,270
reputedly--

915
00:49:02,270 --> 00:49:05,800
and this is, I believe, a true
story-- said, talking about

916
00:49:05,800 --> 00:49:10,770
the snipers from the other side
who were quite far away,

917
00:49:10,770 --> 00:49:13,590
that telling his people, don't
be afraid, they couldn't get

918
00:49:13,590 --> 00:49:15,700
an elephant at this distance.

919
00:49:15,700 --> 00:49:18,780
And if you go to the site of the
battle, you'll find this

920
00:49:18,780 --> 00:49:23,340
plaque describing the death of
John Sedgwick who was shot and

921
00:49:23,340 --> 00:49:29,470
killed immediately upon saying
this by one of said snipers.

922
00:49:29,470 --> 00:49:31,670
It says something about generals
that probably is

923
00:49:31,670 --> 00:49:33,180
still true today.

924
00:49:33,180 --> 00:49:37,760
All right, quick reminders
and then we're done.

925
00:49:37,760 --> 00:49:39,140
There's a final exam.

926
00:49:39,140 --> 00:49:42,100
If you haven't done the
underground guide, go do it.

927
00:49:42,100 --> 00:49:43,940
These are things I said at the
beginning of the lecture.

928
00:49:43,940 --> 00:49:45,480
I'm just repeating them.

929
00:49:45,480 --> 00:49:46,660
Thanks a lot.

930
00:49:46,660 --> 00:49:49,550
Good luck in the final 6.00,
all your finals.

931
00:49:49,550 --> 00:49:51,820
And then more importantly,
have a great summer.