Statistics for Data Science - 1
Professor. Usha Mohan
Department of Management Studies
Indian Institute of Technology, Madras
Lecture No. 10.1
Binomial Distribution- Bernoulli Random Variable
So, we will start understanding about a very important distribution today, and that is the binomial
distribution. The binomial distribution is a discrete distribution, and it arises naturally in a lot of
applications.
(Refer Slide Time: 00:37)
So, the learning objectives are first we go and we are we expect this week, we will first derive
the probability mass function for a binomial distribution. How does the binomial distribution
naturally arise? And then afterwards we will look at understanding the effect of the parameters of
the binomial distribution on the shape of the distribution. We look at the expectation and
variance and how do we answer certain applications based on expectation and variance and
finally, we will understand situations that can be modelled as a binomial distribution.
(Refer Slide Time: 01:16)
So, first we start with a brief review of what is a Bernoulli random variable. If you recall, we
introduced a Bernoulli random variable when we discussed about discrete random variables.
Now, we are going to talk about it in slightly greater detail. Now, a Bernoulli trial or a Bernoulli
experiment is a trial or an experiment whose outcome can be classified as either a success or a
failure. Now, what do we mean by a success or a failure. So, for example, I have a lot of
instances where I can label my outcomes or I can map my outcome to be a success or a failure.
So, if I have a success or a failure, the sample size is going to be success or a failure.
So, recall again I have my sample space which takes the value success. So, recall, I have a
sample space which takes the value success and failure I have a random variable a mapping
success to take the value 1 and failure to take the value 0. So, in other words, a trial or an
experiment which gives me a success or a failure and can be mapped to 1 or 0 for convenience
sake we keep 1 or 0 that is a mapping an outcome to the random variable. So, this X is what we
refer to as our Bernoulli random variable.
(Refer Slide Time: 03:01)
Now, let us look at examples of a Bernoulli trials. We have already looked at a lot of these but
we will review them in the context of a Bernoulli experiment. So, let us start with tossing a coin I
know the outcomes are head and tail. Now, the success can be a head, I can define failure to be a
tail. So, again, this I can call the tossing of a coin once to be a Bernoulli trial.
Now, let us roll a dice I know the outcomes are 1, 2, 3, 4, 5, 6 again I do not have a two
outcomes. But I can define a success to get a 6, in which case the outcomes are going to be just
the singleton 6 and the failure to be any other number. So, you can see that I can define an event
of getting a 6 to be a success and a failure to be getting any other number. So, I can map the
success, success is going to be just the event 6 and the failure is going to be any other number 1,
2, 3, 4, 5.
So, I can define a Bernoulli trial where I define what is a success and failure. Again, opinion
polls, typically you are asking questions where the answers could be yes or no I can define
success to be yes and failure to be no this could be a again applied in a lot of situations for
example political electoral polls, where I am asking whether we are voting for a particular
candidate or not. In that case, yes could mean a success and no could mean a failure.
Again, when you are having a salesperson may selling a particular object a success could be a
sale, a failure could be a no sale. So, again you can see outcome is selling or not selling. So, I can
map it again. I can consider this as a Bernoulli trial. Again testing the effectiveness of a drug in a
pharmaceutical trial, you want to know whether the drug is effective or non effective. Again, I
can define success in this case to be effectiveness of the drug, and failure to be not effectiveness
of drugs. So, you can see that a lot of trials which arise in our day to day lives are actually
Bernoulli trials.
(Refer Slide Time: 05:30)
Let us, look at an example of a non Bernoulli trial, I just randomly choose a person and as their
age, I am see that it is not just two outcomes outcomes are not two age can be anything. So, this
is not a Bernoulli trial, you might argue that okay when a rolled a dice the outcomes are again
not two, number of outcomes are 6. But here I define success to be obtaining a 6 and a failure to
be obtaining anything else. So, the outcomes where mapped to just 2 where I termed success is to
get 6.
So, in other words, I could have written the samples space as getting 6 and not getting 6, two
outcomes. So, a Bernoulli trial depends on how you are defining the outcome. So, getting a 6 and
not 6 are the outcomes, which will define a Bernoulli trial. So, in summary a Bernoulli trial is an
experiment or a trial, which has two outcomes.
(Refer Slide Time: 06:37)
So, random variable. So, now when I have a sample space I have two outcomes, I am defining it
as a success and the failure I am defining the random variable takes the value 1 if it is a success
and 0 it is a failure.
(Refer Slide Time: 6:53)
So, this is what I referred to as a Bernoulli random variable. Further I say X takes the value 1 and
0 it takes only two values so I can say a probability X takes the value 1 let it be p, then this
probability has to be 1 - p because the sum of probabilities have to be equal to 1. So, this gives
me what I refer to as a probability mass function or the probability distribution where probability
X takes the value. So,
takes
equal to 0,
equal to 1 it takes the probability p and 1-p.
Further, we also know what would be the expected value recall expected value of a random
variable
. So, I have an expectation of X, X takes the value 0 with
probability (1 
 p) + 1 * p which will give me the expected value to be p. Now, the
recall the computational formula is [
Now,
the value 0, 1 with the same probability 1-p and p. Hence, [
takes the value 0, 1
. If
again
also takes
, I know
(Refer Slide Time: 8:39)
So, if X is a Bernoulli random variable, I can refer to it as X this is usually used to show the
distribution, it is a Bernoulli random variable the parameter is p the
. So, this way of stating a random variable is say that X is a Bernoulli random variable
with parameter p, the expectation is p and the variances is p(1-p).
(Refer Slide Time: 09:25)
Why a Bernoulli random variables very important and important property as we have seen the
variance of a Bernoulli random variable with parameter p we have just seen was p(1-p). I know p
is a probability with
when
. We know at the extreme case when
again the
So, between
, the
, you see it is a quadratic. So, what
value of p maximises the variance? So, I can just look at it I know that
Now, what is
the first derivative would be
imply?
is what is if
, I equate to at 0 which gives me
implies again recall there are two outcomes, this is a failure
and this is a success with probability half each. So, this tells that the outcomes or the it is equally
likely to fail as it is equally likely to succeed or failure and success has the same probability they
are equally likely to happen. So, when there is an equal likelihood of these outcomes to happen,
you see that is where the variances.
(Refer Slide Time: 11:26)
So, the largest variance of a Bernoulli distribution occurs when
, in other words when
success and failure are equally likely to occur. So, in other words when so the largest variance
say that the uncertainty is very high. So, in most uncertain Bernoulli trials resemble the tosses of
a fair coin because again if you go to a toss of a fair coin I know my sample space is going to be
heads and tails and we also referred this to be success and this to be failure and I know if I have a
fair coin the chance of getting a head is the same as getting as a tail which is half and that is what
this my p which is equally likely to happen. So, the most uncertain Bernoulli trials resemble
outcome or tosses of fair coin.
(Refer Slide Time: 12:33)
So, what we have learned in this section was, we reviewed or revisited the Bernoulli trial excess
a Bernoulli random variable with parameter p, the [ ]
maximised at
, the
, which is
. This is in other words the outcomes are equally likely to happen give me the
most uncertain Bernoulli trials and from this Bernoulli random variable we are going to now
extend the notion of this Bernoulli random variable with two mutually exclusive outcomes to a
binomial random variable.
(Refer Slide Time: 13:26)
But before going to a binomial random variable, we need to understand what do we mean by
independent and identically distributed Bernoulli trials.
