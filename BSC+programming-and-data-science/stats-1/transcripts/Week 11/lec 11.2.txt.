Statistics for Data Science - 1
Professor. Usha Mohan
Department of Management Studies
Indian Institute of Technology, Madras
Lecture No.10.2
Binomial Distribution- Independent and Identically Distributed Bernoulli Trials
(Refer Slide Time: 00:01)
You can see that I can enumerate or I can find out the probability of each of these outcomes and
to compute this probability, I use the fact that the independence of the trials, so I list out the
probability of each of these outcomes. So, you can see that each of these outcomes I have listed
out the probabilities.
But, what is a binomial random variable? The binomial random variable was again a model for
counts what did I count I counted the total number of successes in the outcomes. Now, if I am
going to map it I see in this outcome I have 3 successes. In this outcome I have 2, in this I have 2,
in this I have 1, in this I have 2, in this I have 1, in this I have 1, in this I have no success. So, if
what this counts is the number of successes in these outcomes.
(Refer Slide Time: 01:08)
So, I can map this 
, or the random variable to be the number of successes so I have a 3, 2 ,2, 1,
2, 1, 1, 0 the probability is remain the same. So, I now I can see that the chance of 
, where 
the number of successes taking the value 3, 3 appears only 1 with just 
3 . Now, the chance again
they are independent they are identically distributed the chance of 
 taking the value 2 is equal to
this plus this plus this. So, how many times does that occur? 1, 2, 3 so 1, 2, 3 so it would be
 (1 
Similarly, I see that the chance of 
 taking the value 1 equal to 
 (1 
)2 and that appears 3
times and the chance of 
 taking the value 0 or no success is (1 
)3 . So, I have now what is
what I refer to as the probability distribution of the number of successes in 
 = 3 independent
Bernoulli trials with a 
 which is a probability of success,(
) = (1 
)3 , 3 
)2 , 3 
 (1 
(Refer Slide Time: 3:06)
Now, what I want you to notice is, how did I get this 3, now when I look at the number of successes
is equal to 2. Now, what I mean by number of successes equal to 2 is the way I can I have 3 trials,
I need 2 of these trials to be successful. So, I am in other words I am choosing 2 positions out of
the 3 positions, where I can have a success and I know I can do this in 3
2 ways which is
2!.1!
which is 3 and that reflects in this 3. Similarly, choosing 1 success is also can be done in 
1 way,
which is again the same as 3 and that reflects here.
(Refer Slide Time: 3:54)
So, in other words if I am going to extend the notion of 3 independent trials to 
 independent trials,
again I have trial 1, trial 2, trial 3 up to 
 independent trial each 1 of them results in a success or
failure the probability of getting a success is 
 and failure is (1 
). So, the possible outcome is
I could have all the 
 successes, the probability with which it happens is 
 which is 
The other extreme is all failure, which can happen with probability (1 
 (1 
 (1 
which is (1 
 . I could have my first (
 1) successes and the last failure this would happen
with 
 (1 
) which is 
 (1 
).. In other words, I have to choose (
positions from 
 positions and that can be done in 
 ways or 
1 way.
(Refer Slide Time: 05:16)
So, I can continue it in this form and I can show that the way I have obtain for each of these
outcomes and I have 
 independent trials. So, I have my variable 
, which now takes the value 0
1, 2 up to 
. Now it takes the value 0 with probability (1 
 , it takes the value 
 or all of them
or successes with probability 
 . It takes the value 1 it tells me that if I take the value 1 all I have
 1) failures and 1 success this success can occur in any 1 of these points I can choose it in 1
way, I have 
 (1 
Similarly, 
), I have 
 successive 
 , (
) failures (
) and I can choose this 
successes as 
 way.
(Refer Slide Time: 6:27)
So, this gives me the general formula for the probability of 
 successes and (
) failure to be
 (1 
 and this appears in 
 outcomes. Hence, the probability of 
 successes in 
 trials
 (1 
 . This is the probability mass function of a binomial random variable, 
can take any value 0, 1, 2 up to 
(Refer Slide Time: 07:15)
So, this is how we can see that independent and identically distributed Bernoulli random variables,
how the binomial distribution arises naturally out of these 
 independent trials, where probability
 successes and (
) failures is given by the expression 
) = 
 (1 
this is the key derivation of the binomial probability mass function.
