Statistics for Data Science - 1
Professor. Usha Mohan
Department of Management Studies
Indian Institute of Technology, Madras
Lecture No. 10.5
Binomial distribution - Expectation and variance of Binomial random variable
(Refer Slide Time: 0:16)
In this section we are going to see about how we can compute the expectation and variance of a binomial random variable and
again apply those concepts to answer questions. Now, what is the expectation of a binomial random variable? Now, the
expectation of a binomial random variable is equal to the number of successes, so you know a binomial random variable X is
equal to the way we have defined a binomial random variable, we have defined it as the number of successes in 
 independent
trial, where the probability of a success is 
So, now I can represent, we also said the binomial random variable arises as the sum of 
 independent. Again I am emphasizing
on independent and identically distributed Bernoulli trials. Now, I know that if 
1 , 
2 , 
 are independent Bernoulli trials, it
takes the value 1 with the success 
 and (1 
) that is what because I say the probability of a successes with probability 
Expectation of each 
 again we have computed the expectation of each 
 to be (1 
) which is 
So, I have the expectation of each 
 ,so 
1 ) = 
2 ) = 
 ) = 
. And I am expressing my binomial random variable
as a sum of 
 independent Bernoulli random variables.
(Refer Slide Time: 2:14)
So, once I have this I have my 
 which is expressed as a sum of 
 independent Bernoulli random variables, expectation of each
 equal to 
 again from properties of expectation, remember 
) = 
1 + 
2 + 
 ), which is the expectation of sum
is sum of 
1 ) + 
2 ) + 
 ) each one of them is 
, so I add 
 times to get 
) = 
. The key thing we have used
here is to see the expectation of sum is sum of expectations.
(Refer Slide Time: 3:13)
So, when I am having the sum of expectation, I get 
) = 
. Now, if I am looking at the variance of 
, I again know 
1 + 
2 + 
 ). Now, I am going to use the property of variance which says variance of sum equal to sum of variances
if my 
1 , 
2 , 
 are independent random variables, recall this from our properties of variance, if I have 
 independent random
variables then variance of sum is the sum of variances.
I use this then I get that 
1 + 
2 + 
 ) = 
1 ) + 
2 ) + 
 ). Now, 
1 is taking the value 1 and 0,
 take the value 1 and 0 with probability 
 and (1 
), we have already seen that 
 ) is going to be 
) that is the
variance of a Bernoulli random variable. So, 
1 ) = 
2 ) = 
 ) = 
), giving the
) = 
), (Refer Slide Time: 4:50)
So, I find 
) = 
) = 
. So, the key result is we use the fact that expectation of sum is the sum of expectation
we get 
) = 
 and using the fact that the variance of sum of independent random variables is equal to sum of variances we
get 
) = 
So, in summary if I have 
 which is a binomial random variable with parameters 
 and 
, the 
) = 
 and the 
). Remember I am using 
), I use 
), or 
), both of them represent the same.
(Refer Slide Time: 5:52)
So, now let us look at a few examples and understand how to use this concept of expectation and variance. I am tossing a coin
500 time, again each time I toss a coin I know I have a Bernoulli trial, it is a fair coin then I have each of my times 
 is a
Bernoulli trial with parameter 1/2. So, if I am tossing a coin 500 time, my 
 is 500. So, if I am counting the number of successes
then 
 is a binomial with parameter 500 and 1/2.
(Refer Slide Time: 6:33)
So, if I am tossing a fair coin then 
 = 1/2, 500 time the question is what is the standard deviation of the number of times a head
appears. Again if 
 is the number of times a head appears, I know 
 is a binomial with parameter 500 and 1/2, 1/2 because I
have a fair coin, 
 = 500, 
 = 1/2, my 
) = 500 
 (2) = 250. The way I can interpret this if I keep tossing a coin 500
times I can expect 250 of the outcomes to be head. The variance of 
 is going to be 
) which is 125. The standard
deviation of 
 is 
125. So, I get the standard deviation of 
 is around 11.1803.
(Refer Slide Time: 8:00)
So, now the other thing is given the expectation and the value of 
, can I find the probability? What does this mean? Again if I
know 
 is a binomial random variable with parameter 
 and 
. So, I am not given 
 and 
, but I am given 
) and I know 
Can I determine 
? The answer is yes, because I know, if I know 
) I know 
, I know 
, I can solve for 
So, given 
 and 
, I have to find 
, that is what it is telling me. So, again the expected number of heads in a series of 10 tosses
is 6, what is the probability that there are 8 heads? So, first step 
 is a binomial. Again I know it, the experiment is a binomial
experiment because I am tossing a fair coin 10 times, am I tossing it 10 times, is it fair? We do not know, but I am just trying to,
I need to identify what is my 
So, it is not telling whether, it is just telling a coin, it is not specifying whether it is a fair coin. But I know 
 = 10, let me keep
 as it is, I am interested in knowing what is the probability that there are 8 heads where 
 is the number of heads or successes
in 10 tosses? What else is given to us? 
) = 6, that is what we are given. I know if 
 is a binomial with parameter 
 and 
 is the expected value of X which is given to be equal to 6, I have 
 equal to 10 so 10
 = 6, which gives 
 = 10 = 0.6 .
(Refer Slide Time: 10:27)
So, I can identify the distribution of the number of heads as 
 is a binomial with parameter 
 = 10, p=6/10. I can identify my
 = 10, 
 = 10). Now, I want to know what is the probability that there are 8 heads, so I am interested in knowing
this, I can see that 
), I know that the 
) = (
 (1 
 = 10, 
 = 8, so I get 
 = 8) =
8)(10)8 (1 
 10)
)0.68 (0.4)2
which you can verify is equal to 0.121, I leave this as an exercise to verify that 
 = 8) =
= 0.121.
(Refer Slide Time: 12:00)
Now, sometimes we are given expectation and variance of a random variable. So, again if I know 
) = 
). So, given 
 and 
). So, suppose I am given this is A and this is B, I can solve for 
 which
is very simple, I know that 
, so I know 
) = 
, which gives 1 
 or 
 = 1 
So, we can solve for 
 once I know 
, I can solve for 
, I know already 
 = 1 
. So, given the expectation
and variance I can solve for both 
 and 
. I can solve for 
 and 
. Now, if I am given 
 and 
, I can find out what is the probability
mass function of the binomial random variable.
(Refer Slide Time: 13:28)
Now, let us look at an example, I know that 
 is a binomial random variable, 
 = 4.5, 
) = 0.45, this is the expected
0.45
value and this is my variance. So, from these two, I can obtain that 4.5
) = 0.45 which gives me, 1 
 = 4.5 which
0.45
gives me that 
 equals to, which gives me 1 
 = 4.5 , so 
 = 10. If 
 = 10, I know 
 10 = 4.5, which gives me 
 = 5. So, I
have 
 is a binomial random variable with parameter 
 = 5, 
 = 0.9.
(Refer Slide Time: 14:59)
I can verify the expected value is 4.5 which is 
, so I can verify 
 is 4.5 which is what I have here 
) = 4.5 
 0.1 =
0.45, which is what I have here.
(Refer Slide Time: 15:22)
So, once I identify and solve for the unknowns 
 and 
, I am interested in knowing what is 
 = 3), I know 
 is a binomial
with parameter 5 and 0.9, 
 = 3) = (53)(0.9)3 (0.1)2 which I am going to get and I can verify that, that is 0.0729.
Similarly, I leave it as an exercise 
 4) = 
 = 4) + 
 = 5), 
 = 4) = (54)(0.9)4 (0.1)1 , 
 = 5) = (55)(0.9)5
and we can verify that 
 4) is 0.9185, which is the answer I get here. So, given the expectation and variance I can obtain
the probability distribution of my random variable.
(Refer Slide Time: 16:40)
So, in summary what we have learnt here is what are expectation and variance of a binomial random variable. Remember if 
a binomial random variable with parameter 
 and 
) = 
) = 
). So, given the expectation and 
 we saw
how to obtain 
, given expectation and variance you can solve for both 
 and 
 and obtain the probability distribution.
So, with this we complete the discussion on binomial distribution. So, the path we took was, we looked at discrete random
variables and in the real, in the domain of discrete random variables, we focused on mainly certain applications which follow
the binomial distribution. The next thing we are going to discuss is about continuous random variables.
